Data Distribution For Training Phase
Images 812
Masks 812
Data Distribution For Validation Phase
Images 91
Masks 91
Feature info [{'num_chs': 64, 'reduction': 2, 'module': 'stem'}, {'num_chs': 128, 'reduction': 4, 'module': 'stage1'}, {'num_chs': 256, 'reduction': 8, 'module': 'stage2'}, {'num_chs': 512, 'reduction': 16, 'module': 'stage3'}, {'num_chs': 1024, 'reduction': 32, 'module': 'stage4'}]
Feature info [{'num_chs': 64, 'reduction': 2, 'module': 'stem'}, {'num_chs': 128, 'reduction': 4, 'module': 'stage1'}, {'num_chs': 256, 'reduction': 8, 'module': 'stage2'}, {'num_chs': 512, 'reduction': 16, 'module': 'stage3'}, {'num_chs': 1024, 'reduction': 32, 'module': 'stage4'}]
Model UnetPlusPlus(
  (encoder): HighResolutionNetFeatures(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU(inplace=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU(inplace=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (3): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
    )
    (transition1): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage2): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (3): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (transition3): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (incre_modules): ModuleList(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=128, out_features=8, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=8, out_features=128, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=256, out_features=16, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=16, out_features=256, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=512, out_features=32, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=32, out_features=512, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=1024, out_features=64, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=64, out_features=1024, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
    )
  )
  (decoder): UnetPlusPlusDecoder(
    (center): Identity()
    (blocks): ModuleDict(
      (x_0_0): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_2_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_2_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_3_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_4): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
    )
  )
  (segmentation_head): SegmentationHead(
    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Identity()
    (2): Activation(
      (activation): Identity()
    )
  )
)
Number of train batches: 407
Number of val batches: 92
Adjusting learning rate of group 0 to 1.0000e-03.
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|                                                                                                                               | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                                                                  | 0/2 [00:00<?, ?it/s]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])
Sanity Checking DataLoader 0:  50%|                                                     | 1/2 [00:00<00:00,  1.28it/s]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])
Sanity Checking DataLoader 0: 100%|| 2/2 [00:01<00:00,  1.87it/s]                                                                                                                                                                           Training: 0it [00:00, ?it/s]Training:   0%|                                                                                                                                    | 0/497 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                                                     | 0/497 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                                            | 1/497 [00:01<10:18,  1.25s/it]Epoch 0:   0%|                                                                                                       | 1/497 [00:01<10:18,  1.25s/it, loss=1.54, v_num=75]Epoch 0:   0%|                                                                                                       | 2/497 [00:02<09:51,  1.19s/it, loss=1.54, v_num=75]Epoch 0:   0%|                                                                                                       | 2/497 [00:02<09:51,  1.19s/it, loss=1.22, v_num=75]Epoch 0:   1%|                                                                                                       | 3/497 [00:03<09:41,  1.18s/it, loss=1.22, v_num=75]Epoch 0:   1%|                                                                                                       | 3/497 [00:03<09:41,  1.18s/it, loss=1.19, v_num=75]Epoch 0:   1%|                                                                                                       | 4/497 [00:04<09:34,  1.17s/it, loss=1.19, v_num=75]Epoch 0:   1%|                                                                                                       | 4/497 [00:04<09:34,  1.17s/it, loss=1.05, v_num=75]Epoch 0:   1%|                                                                                                       | 5/497 [00:05<09:30,  1.16s/it, loss=1.05, v_num=75]Epoch 0:   1%|                                                                                                       | 5/497 [00:05<09:30,  1.16s/it, loss=1.03, v_num=75]Epoch 0:   1%|                                                                                                      | 6/497 [00:06<09:27,  1.16s/it, loss=1.03, v_num=75]Epoch 0:   1%|                                                                                                     | 6/497 [00:06<09:27,  1.16s/it, loss=0.982, v_num=75]Epoch 0:   1%|                                                                                                     | 7/497 [00:08<09:25,  1.15s/it, loss=0.982, v_num=75]Epoch 0:   1%|                                                                                                     | 7/497 [00:08<09:25,  1.15s/it, loss=0.953, v_num=75]Epoch 0:   2%|                                                                                                     | 8/497 [00:09<09:23,  1.15s/it, loss=0.953, v_num=75]Epoch 0:   2%|                                                                                                     | 8/497 [00:09<09:23,  1.15s/it, loss=0.911, v_num=75]Epoch 0:   2%|                                                                                                     | 9/497 [00:10<09:21,  1.15s/it, loss=0.911, v_num=75]Epoch 0:   2%|                                                                                                     | 9/497 [00:10<09:21,  1.15s/it, loss=0.873, v_num=75]Epoch 0:   2%|                                                                                                    | 10/497 [00:11<09:20,  1.15s/it, loss=0.873, v_num=75]Epoch 0:   2%|                                                                                                    | 10/497 [00:11<09:20,  1.15s/it, loss=0.835, v_num=75]Epoch 0:   2%|                                                                                                   | 11/497 [00:12<09:18,  1.15s/it, loss=0.835, v_num=75]Epoch 0:   2%|                                                                                                   | 11/497 [00:12<09:18,  1.15s/it, loss=0.807, v_num=75]Epoch 0:   2%|                                                                                                   | 12/497 [00:13<09:17,  1.15s/it, loss=0.807, v_num=75]Epoch 0:   2%|                                                                                                    | 12/497 [00:13<09:17,  1.15s/it, loss=0.78, v_num=75]Epoch 0:   3%|                                                                                                    | 13/497 [00:14<09:15,  1.15s/it, loss=0.78, v_num=75]Epoch 0:   3%|                                                                                                   | 13/497 [00:14<09:15,  1.15s/it, loss=0.752, v_num=75]Epoch 0:   3%|                                                                                                   | 14/497 [00:16<09:14,  1.15s/it, loss=0.752, v_num=75]Epoch 0:   3%|                                                                                                   | 14/497 [00:16<09:14,  1.15s/it, loss=0.729, v_num=75]Epoch 0:   3%|                                                                                                   | 15/497 [00:17<09:12,  1.15s/it, loss=0.729, v_num=75]Epoch 0:   3%|                                                                                                   | 15/497 [00:17<09:12,  1.15s/it, loss=0.711, v_num=75]Epoch 0:   3%|                                                                                                  | 16/497 [00:18<09:11,  1.15s/it, loss=0.711, v_num=75]Epoch 0:   3%|                                                                                                  | 16/497 [00:18<09:11,  1.15s/it, loss=0.687, v_num=75]Epoch 0:   3%|                                                                                                  | 17/497 [00:19<09:10,  1.15s/it, loss=0.687, v_num=75]Epoch 0:   3%|                                                                                                  | 17/497 [00:19<09:10,  1.15s/it, loss=0.666, v_num=75]Epoch 0:   4%|                                                                                                  | 18/497 [00:20<09:09,  1.15s/it, loss=0.666, v_num=75]Epoch 0:   4%|                                                                                                  | 18/497 [00:20<09:09,  1.15s/it, loss=0.649, v_num=75]Epoch 0:   4%|                                                                                                  | 19/497 [00:21<09:08,  1.15s/it, loss=0.649, v_num=75]Epoch 0:   4%|                                                                                                   | 19/497 [00:21<09:08,  1.15s/it, loss=0.63, v_num=75]Epoch 0:   4%|                                                                                                  | 20/497 [00:22<09:06,  1.15s/it, loss=0.63, v_num=75]Epoch 0:   4%|                                                                                                  | 20/497 [00:22<09:06,  1.15s/it, loss=0.613, v_num=75]Epoch 0:   4%|                                                                                                 | 21/497 [00:24<09:05,  1.15s/it, loss=0.613, v_num=75]Epoch 0:   4%|                                                                                                 | 21/497 [00:24<09:05,  1.15s/it, loss=0.549, v_num=75]Epoch 0:   4%|                                                                                                 | 22/497 [00:25<09:04,  1.15s/it, loss=0.549, v_num=75]Epoch 0:   4%|                                                                                                 | 22/497 [00:25<09:04,  1.15s/it, loss=0.517, v_num=75]Epoch 0:   5%|                                                                                                 | 23/497 [00:26<09:03,  1.15s/it, loss=0.517, v_num=75]Epoch 0:   5%|                                                                                                 | 23/497 [00:26<09:03,  1.15s/it, loss=0.471, v_num=75]Epoch 0:   5%|                                                                                                 | 24/497 [00:27<09:02,  1.15s/it, loss=0.471, v_num=75]Epoch 0:   5%|                                                                                                 | 24/497 [00:27<09:02,  1.15s/it, loss=0.458, v_num=75]Epoch 0:   5%|                                                                                                | 25/497 [00:28<09:01,  1.15s/it, loss=0.458, v_num=75]Epoch 0:   5%|                                                                                                | 25/497 [00:28<09:01,  1.15s/it, loss=0.421, v_num=75]Epoch 0:   5%|                                                                                                | 26/497 [00:29<09:00,  1.15s/it, loss=0.421, v_num=75]Epoch 0:   5%|                                                                                                | 26/497 [00:29<09:00,  1.15s/it, loss=0.396, v_num=75]Epoch 0:   5%|                                                                                                | 27/497 [00:30<08:59,  1.15s/it, loss=0.396, v_num=75]Epoch 0:   5%|                                                                                                | 27/497 [00:30<08:59,  1.15s/it, loss=0.366, v_num=75]Epoch 0:   6%|                                                                                                | 28/497 [00:32<08:58,  1.15s/it, loss=0.366, v_num=75]Epoch 0:   6%|                                                                                                | 28/497 [00:32<08:58,  1.15s/it, loss=0.346, v_num=75]Epoch 0:   6%|                                                                                                | 29/497 [00:33<08:56,  1.15s/it, loss=0.346, v_num=75]Epoch 0:   6%|                                                                                                | 29/497 [00:33<08:56,  1.15s/it, loss=0.328, v_num=75]Epoch 0:   6%|                                                                                               | 30/497 [00:34<08:55,  1.15s/it, loss=0.328, v_num=75]Epoch 0:   6%|                                                                                               | 30/497 [00:34<08:55,  1.15s/it, loss=0.318, v_num=75]Epoch 0:   6%|                                                                                               | 31/497 [00:35<08:54,  1.15s/it, loss=0.318, v_num=75]Epoch 0:   6%|                                                                                                 | 31/497 [00:35<08:54,  1.15s/it, loss=0.3, v_num=75]Epoch 0:   6%|                                                                                                 | 32/497 [00:36<08:53,  1.15s/it, loss=0.3, v_num=75]Epoch 0:   6%|                                                                                               | 32/497 [00:36<08:53,  1.15s/it, loss=0.285, v_num=75]Epoch 0:   7%|                                                                                               | 33/497 [00:37<08:52,  1.15s/it, loss=0.285, v_num=75]Epoch 0:   7%|                                                                                               | 33/497 [00:37<08:52,  1.15s/it, loss=0.271, v_num=75]Epoch 0:   7%|                                                                                               | 34/497 [00:39<08:51,  1.15s/it, loss=0.271, v_num=75]Epoch 0:   7%|                                                                                               | 34/497 [00:39<08:51,  1.15s/it, loss=0.258, v_num=75]Epoch 0:   7%|                                                                                              | 35/497 [00:40<08:50,  1.15s/it, loss=0.258, v_num=75]Epoch 0:   7%|                                                                                               | 35/497 [00:40<08:50,  1.15s/it, loss=0.25, v_num=75]Epoch 0:   7%|                                                                                               | 36/497 [00:41<08:49,  1.15s/it, loss=0.25, v_num=75]Epoch 0:   7%|                                                                                              | 36/497 [00:41<08:49,  1.15s/it, loss=0.257, v_num=75]Epoch 0:   7%|                                                                                              | 37/497 [00:42<08:48,  1.15s/it, loss=0.257, v_num=75]Epoch 0:   7%|                                                                                              | 37/497 [00:42<08:48,  1.15s/it, loss=0.262, v_num=75]Epoch 0:   8%|                                                                                              | 38/497 [00:43<08:47,  1.15s/it, loss=0.262, v_num=75]Epoch 0:   8%|                                                                                              | 38/497 [00:43<08:47,  1.15s/it, loss=0.249, v_num=75]Epoch 0:   8%|                                                                                              | 39/497 [00:44<08:46,  1.15s/it, loss=0.249, v_num=75]Epoch 0:   8%|                                                                                              | 39/497 [00:44<08:46,  1.15s/it, loss=0.245, v_num=75]Epoch 0:   8%|                                                                                             | 40/497 [00:45<08:45,  1.15s/it, loss=0.245, v_num=75]Epoch 0:   8%|                                                                                             | 40/497 [00:45<08:45,  1.15s/it, loss=0.239, v_num=75]Epoch 0:   8%|                                                                                             | 41/497 [00:47<08:44,  1.15s/it, loss=0.239, v_num=75]Epoch 0:   8%|                                                                                              | 41/497 [00:47<08:44,  1.15s/it, loss=0.24, v_num=75]Epoch 0:   8%|                                                                                              | 42/497 [00:48<08:43,  1.15s/it, loss=0.24, v_num=75]Epoch 0:   8%|                                                                                             | 42/497 [00:48<08:43,  1.15s/it, loss=0.251, v_num=75]Epoch 0:   9%|                                                                                             | 43/497 [00:49<08:42,  1.15s/it, loss=0.251, v_num=75]Epoch 0:   9%|                                                                                              | 43/497 [00:49<08:42,  1.15s/it, loss=0.25, v_num=75]Epoch 0:   9%|                                                                                              | 44/497 [00:50<08:41,  1.15s/it, loss=0.25, v_num=75]Epoch 0:   9%|                                                                                             | 44/497 [00:50<08:41,  1.15s/it, loss=0.239, v_num=75]Epoch 0:   9%|                                                                                            | 45/497 [00:51<08:40,  1.15s/it, loss=0.239, v_num=75]Epoch 0:   9%|                                                                                            | 45/497 [00:51<08:40,  1.15s/it, loss=0.236, v_num=75]Epoch 0:   9%|                                                                                            | 46/497 [00:52<08:39,  1.15s/it, loss=0.236, v_num=75]Epoch 0:   9%|                                                                                             | 46/497 [00:52<08:39,  1.15s/it, loss=0.23, v_num=75]Epoch 0:   9%|                                                                                             | 47/497 [00:54<08:37,  1.15s/it, loss=0.23, v_num=75]Epoch 0:   9%|                                                                                             | 47/497 [00:54<08:38,  1.15s/it, loss=0.23, v_num=75]Epoch 0:  10%|                                                                                             | 48/497 [00:55<08:36,  1.15s/it, loss=0.23, v_num=75]Epoch 0:  10%|                                                                                            | 48/497 [00:55<08:36,  1.15s/it, loss=0.229, v_num=75]Epoch 0:  10%|                                                                                            | 49/497 [00:56<08:35,  1.15s/it, loss=0.229, v_num=75]Epoch 0:  10%|                                                                                            | 49/497 [00:56<08:35,  1.15s/it, loss=0.233, v_num=75]Epoch 0:  10%|                                                                                           | 50/497 [00:57<08:34,  1.15s/it, loss=0.233, v_num=75]Epoch 0:  10%|                                                                                           | 50/497 [00:57<08:34,  1.15s/it, loss=0.226, v_num=75]Epoch 0:  10%|                                                                                           | 51/497 [00:58<08:33,  1.15s/it, loss=0.226, v_num=75]Epoch 0:  10%|                                                                                           | 51/497 [00:58<08:33,  1.15s/it, loss=0.227, v_num=75]Epoch 0:  10%|                                                                                           | 52/497 [00:59<08:32,  1.15s/it, loss=0.227, v_num=75]Epoch 0:  10%|                                                                                           | 52/497 [00:59<08:32,  1.15s/it, loss=0.229, v_num=75]Epoch 0:  11%|                                                                                           | 53/497 [01:01<08:31,  1.15s/it, loss=0.229, v_num=75]Epoch 0:  11%|                                                                                            | 53/497 [01:01<08:31,  1.15s/it, loss=0.24, v_num=75]Epoch 0:  11%|                                                                                           | 54/497 [01:02<08:30,  1.15s/it, loss=0.24, v_num=75]Epoch 0:  11%|                                                                                           | 54/497 [01:02<08:30,  1.15s/it, loss=0.239, v_num=75]Epoch 0:  11%|                                                                                          | 55/497 [01:03<08:29,  1.15s/it, loss=0.239, v_num=75]Epoch 0:  11%|                                                                                          | 55/497 [01:03<08:29,  1.15s/it, loss=0.233, v_num=75]Epoch 0:  11%|                                                                                          | 56/497 [01:04<08:28,  1.15s/it, loss=0.233, v_num=75]Epoch 0:  11%|                                                                                          | 56/497 [01:04<08:28,  1.15s/it, loss=0.218, v_num=75]Epoch 0:  11%|                                                                                          | 57/497 [01:05<08:27,  1.15s/it, loss=0.218, v_num=75]Epoch 0:  11%|                                                                                          | 57/497 [01:05<08:27,  1.15s/it, loss=0.207, v_num=75]Epoch 0:  12%|                                                                                          | 58/497 [01:06<08:26,  1.15s/it, loss=0.207, v_num=75]Epoch 0:  12%|                                                                                          | 58/497 [01:06<08:26,  1.15s/it, loss=0.209, v_num=75]Epoch 0:  12%|                                                                                          | 59/497 [01:08<08:25,  1.15s/it, loss=0.209, v_num=75]Epoch 0:  12%|                                                                                          | 59/497 [01:08<08:25,  1.15s/it, loss=0.209, v_num=75]Epoch 0:  12%|                                                                                         | 60/497 [01:09<08:24,  1.15s/it, loss=0.209, v_num=75]Epoch 0:  12%|                                                                                         | 60/497 [01:09<08:24,  1.15s/it, loss=0.211, v_num=75]Epoch 0:  12%|                                                                                         | 61/497 [01:10<08:23,  1.15s/it, loss=0.211, v_num=75]Epoch 0:  12%|                                                                                         | 61/497 [01:10<08:23,  1.15s/it, loss=0.202, v_num=75]Epoch 0:  12%|                                                                                         | 62/497 [01:11<08:22,  1.16s/it, loss=0.202, v_num=75]Epoch 0:  12%|                                                                                         | 62/497 [01:11<08:22,  1.16s/it, loss=0.184, v_num=75]Epoch 0:  13%|                                                                                         | 63/497 [01:12<08:21,  1.16s/it, loss=0.184, v_num=75]Epoch 0:  13%|                                                                                         | 63/497 [01:12<08:21,  1.16s/it, loss=0.178, v_num=75]Epoch 0:  13%|                                                                                        | 64/497 [01:13<08:20,  1.16s/it, loss=0.178, v_num=75]Epoch 0:  13%|                                                                                        | 64/497 [01:13<08:20,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  13%|                                                                                        | 65/497 [01:15<08:19,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  13%|                                                                                        | 65/497 [01:15<08:19,  1.16s/it, loss=0.172, v_num=75]Epoch 0:  13%|                                                                                        | 66/497 [01:16<08:18,  1.16s/it, loss=0.172, v_num=75]Epoch 0:  13%|                                                                                        | 66/497 [01:16<08:18,  1.16s/it, loss=0.171, v_num=75]Epoch 0:  13%|                                                                                        | 67/497 [01:17<08:17,  1.16s/it, loss=0.171, v_num=75]Epoch 0:  13%|                                                                                        | 67/497 [01:17<08:17,  1.16s/it, loss=0.166, v_num=75]Epoch 0:  14%|                                                                                        | 68/497 [01:18<08:16,  1.16s/it, loss=0.166, v_num=75]Epoch 0:  14%|                                                                                        | 68/497 [01:18<08:16,  1.16s/it, loss=0.185, v_num=75]Epoch 0:  14%|                                                                                       | 69/497 [01:19<08:15,  1.16s/it, loss=0.185, v_num=75]Epoch 0:  14%|                                                                                       | 69/497 [01:19<08:15,  1.16s/it, loss=0.179, v_num=75]Epoch 0:  14%|                                                                                       | 70/497 [01:21<08:14,  1.16s/it, loss=0.179, v_num=75]Epoch 0:  14%|                                                                                       | 70/497 [01:21<08:14,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  14%|                                                                                       | 71/497 [01:22<08:13,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  14%|                                                                                       | 71/497 [01:22<08:13,  1.16s/it, loss=0.186, v_num=75]Epoch 0:  14%|                                                                                       | 72/497 [01:23<08:12,  1.16s/it, loss=0.186, v_num=75]Epoch 0:  14%|                                                                                        | 72/497 [01:23<08:12,  1.16s/it, loss=0.18, v_num=75]Epoch 0:  15%|                                                                                       | 73/497 [01:24<08:11,  1.16s/it, loss=0.18, v_num=75]Epoch 0:  15%|                                                                                       | 73/497 [01:24<08:11,  1.16s/it, loss=0.176, v_num=75]Epoch 0:  15%|                                                                                      | 74/497 [01:25<08:10,  1.16s/it, loss=0.176, v_num=75]Epoch 0:  15%|                                                                                      | 74/497 [01:25<08:10,  1.16s/it, loss=0.173, v_num=75]Epoch 0:  15%|                                                                                      | 75/497 [01:26<08:09,  1.16s/it, loss=0.173, v_num=75]Epoch 0:  15%|                                                                                      | 75/497 [01:26<08:09,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  15%|                                                                                      | 76/497 [01:28<08:08,  1.16s/it, loss=0.174, v_num=75]Epoch 0:  15%|                                                                                      | 76/497 [01:28<08:08,  1.16s/it, loss=0.176, v_num=75]Epoch 0:  15%|                                                                                      | 77/497 [01:29<08:07,  1.16s/it, loss=0.176, v_num=75]Epoch 0:  15%|                                                                                      | 77/497 [01:29<08:07,  1.16s/it, loss=0.175, v_num=75]Epoch 0:  16%|                                                                                      | 78/497 [01:30<08:06,  1.16s/it, loss=0.175, v_num=75]Epoch 0:  16%|                                                                                      | 78/497 [01:30<08:06,  1.16s/it, loss=0.173, v_num=75]Epoch 0:  16%|                                                                                     | 79/497 [01:31<08:05,  1.16s/it, loss=0.173, v_num=75]Epoch 0:  16%|                                                                                     | 79/497 [01:31<08:05,  1.16s/it, loss=0.171, v_num=75]Epoch 0:  16%|                                                                                     | 80/497 [01:32<08:04,  1.16s/it, loss=0.171, v_num=75]Epoch 0:  16%|                                                                                     | 80/497 [01:32<08:04,  1.16s/it, loss=0.167, v_num=75]Epoch 0:  16%|                                                                                     | 81/497 [01:34<08:03,  1.16s/it, loss=0.167, v_num=75]Epoch 0:  16%|                                                                                      | 81/497 [01:34<08:03,  1.16s/it, loss=0.17, v_num=75]Epoch 0:  16%|                                                                                      | 82/497 [01:35<08:02,  1.16s/it, loss=0.17, v_num=75]Epoch 0:  16%|                                                                                     | 82/497 [01:35<08:02,  1.16s/it, loss=0.172, v_num=75]Epoch 0:  17%|                                                                                     | 83/497 [01:36<08:01,  1.16s/it, loss=0.172, v_num=75]Epoch 0:  17%|                                                                                     | 83/497 [01:36<08:01,  1.16s/it, loss=0.175, v_num=75]Epoch 0:  17%|                                                                                    | 84/497 [01:37<08:00,  1.16s/it, loss=0.175, v_num=75]Epoch 0:  17%|                                                                                    | 84/497 [01:37<08:00,  1.16s/it, loss=0.178, v_num=75]Epoch 0:  17%|                                                                                    | 85/497 [01:38<07:58,  1.16s/it, loss=0.178, v_num=75]Epoch 0:  17%|                                                                                    | 85/497 [01:38<07:58,  1.16s/it, loss=0.184, v_num=75]Epoch 0:  17%|                                                                                    | 86/497 [01:40<07:57,  1.16s/it, loss=0.184, v_num=75]Epoch 0:  17%|                                                                                    | 86/497 [01:40<07:57,  1.16s/it, loss=0.186, v_num=75]Epoch 0:  18%|                                                                                    | 87/497 [01:41<07:56,  1.16s/it, loss=0.186, v_num=75]Epoch 0:  18%|                                                                                    | 87/497 [01:41<07:56,  1.16s/it, loss=0.189, v_num=75]Epoch 0:  18%|                                                                                    | 88/497 [01:42<07:55,  1.16s/it, loss=0.189, v_num=75]Epoch 0:  18%|                                                                                    | 88/497 [01:42<07:55,  1.16s/it, loss=0.165, v_num=75]Epoch 0:  18%|                                                                                   | 89/497 [01:43<07:54,  1.16s/it, loss=0.165, v_num=75]Epoch 0:  18%|                                                                                   | 89/497 [01:43<07:54,  1.16s/it, loss=0.168, v_num=75]Epoch 0:  18%|                                                                                   | 90/497 [01:44<07:53,  1.16s/it, loss=0.168, v_num=75]Epoch 0:  18%|                                                                                    | 90/497 [01:44<07:53,  1.16s/it, loss=0.17, v_num=75]Epoch 0:  18%|                                                                                    | 91/497 [01:45<07:52,  1.16s/it, loss=0.17, v_num=75]Epoch 0:  18%|                                                                                   | 91/497 [01:45<07:52,  1.16s/it, loss=0.153, v_num=75]Epoch 0:  19%|                                                                                   | 92/497 [01:47<07:51,  1.16s/it, loss=0.153, v_num=75]Epoch 0:  19%|                                                                                   | 92/497 [01:47<07:51,  1.16s/it, loss=0.153, v_num=75]Epoch 0:  19%|                                                                                   | 93/497 [01:48<07:50,  1.17s/it, loss=0.153, v_num=75]Epoch 0:  19%|                                                                                   | 93/497 [01:48<07:50,  1.17s/it, loss=0.163, v_num=75]Epoch 0:  19%|                                                                                  | 94/497 [01:49<07:49,  1.17s/it, loss=0.163, v_num=75]Epoch 0:  19%|                                                                                  | 94/497 [01:49<07:49,  1.17s/it, loss=0.165, v_num=75]Epoch 0:  19%|                                                                                  | 95/497 [01:50<07:48,  1.17s/it, loss=0.165, v_num=75]Epoch 0:  19%|                                                                                  | 95/497 [01:50<07:48,  1.17s/it, loss=0.159, v_num=75]Epoch 0:  19%|                                                                                  | 96/497 [01:51<07:47,  1.17s/it, loss=0.159, v_num=75]Epoch 0:  19%|                                                                                  | 96/497 [01:51<07:47,  1.17s/it, loss=0.155, v_num=75]Epoch 0:  20%|                                                                                  | 97/497 [01:53<07:46,  1.17s/it, loss=0.155, v_num=75]Epoch 0:  20%|                                                                                  | 97/497 [01:53<07:46,  1.17s/it, loss=0.153, v_num=75]Epoch 0:  20%|                                                                                  | 98/497 [01:54<07:45,  1.17s/it, loss=0.153, v_num=75]Epoch 0:  20%|                                                                                  | 98/497 [01:54<07:45,  1.17s/it, loss=0.156, v_num=75]Epoch 0:  20%|                                                                                 | 99/497 [01:55<07:44,  1.17s/it, loss=0.156, v_num=75]Epoch 0:  20%|                                                                                 | 99/497 [01:55<07:44,  1.17s/it, loss=0.164, v_num=75]Epoch 0:  20%|                                                                                | 100/497 [01:56<07:43,  1.17s/it, loss=0.164, v_num=75]Epoch 0:  20%|                                                                                | 100/497 [01:56<07:43,  1.17s/it, loss=0.171, v_num=75]Epoch 0:  20%|                                                                                | 101/497 [01:57<07:42,  1.17s/it, loss=0.171, v_num=75]Epoch 0:  20%|                                                                                | 101/497 [01:57<07:42,  1.17s/it, loss=0.174, v_num=75]Epoch 0:  21%|                                                                                | 102/497 [01:59<07:41,  1.17s/it, loss=0.174, v_num=75]Epoch 0:  21%|                                                                                | 102/497 [01:59<07:41,  1.17s/it, loss=0.175, v_num=75]Epoch 0:  21%|                                                                                | 103/497 [02:00<07:40,  1.17s/it, loss=0.175, v_num=75]Epoch 0:  21%|                                                                                | 103/497 [02:00<07:40,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  21%|                                                                               | 104/497 [02:01<07:39,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  21%|                                                                               | 104/497 [02:01<07:39,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  21%|                                                                               | 105/497 [02:02<07:38,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  21%|                                                                               | 105/497 [02:02<07:38,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  21%|                                                                               | 106/497 [02:03<07:37,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  21%|                                                                               | 106/497 [02:03<07:37,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  22%|                                                                               | 107/497 [02:05<07:36,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  22%|                                                                               | 107/497 [02:05<07:36,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  22%|                                                                               | 108/497 [02:06<07:35,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  22%|                                                                               | 108/497 [02:06<07:35,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  22%|                                                                              | 109/497 [02:07<07:34,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  22%|                                                                              | 109/497 [02:07<07:34,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  22%|                                                                              | 110/497 [02:08<07:33,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  22%|                                                                              | 110/497 [02:08<07:33,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  22%|                                                                              | 111/497 [02:09<07:31,  1.17s/it, loss=0.172, v_num=75]Epoch 0:  22%|                                                                              | 111/497 [02:09<07:31,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  23%|                                                                              | 112/497 [02:11<07:30,  1.17s/it, loss=0.173, v_num=75]Epoch 0:  23%|                                                                              | 112/497 [02:11<07:30,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  23%|                                                                              | 113/497 [02:12<07:29,  1.17s/it, loss=0.176, v_num=75]Epoch 0:  23%|                                                                              | 113/497 [02:12<07:29,  1.17s/it, loss=0.157, v_num=75]Epoch 0:  23%|                                                                             | 114/497 [02:13<07:28,  1.17s/it, loss=0.157, v_num=75]Epoch 0:  23%|                                                                             | 114/497 [02:13<07:28,  1.17s/it, loss=0.154, v_num=75]Epoch 0:  23%|                                                                             | 115/497 [02:14<07:27,  1.17s/it, loss=0.154, v_num=75]Epoch 0:  23%|                                                                             | 115/497 [02:14<07:27,  1.17s/it, loss=0.159, v_num=75]Epoch 0:  23%|                                                                             | 116/497 [02:15<07:26,  1.17s/it, loss=0.159, v_num=75]Epoch 0:  23%|                                                                             | 116/497 [02:15<07:26,  1.17s/it, loss=0.158, v_num=75]Epoch 0:  24%|                                                                             | 117/497 [02:17<07:25,  1.17s/it, loss=0.158, v_num=75]Epoch 0:  24%|                                                                             | 117/497 [02:17<07:25,  1.17s/it, loss=0.158, v_num=75]Epoch 0:  24%|                                                                             | 118/497 [02:18<07:24,  1.17s/it, loss=0.158, v_num=75]Epoch 0:  24%|                                                                             | 118/497 [02:18<07:24,  1.17s/it, loss=0.151, v_num=75]Epoch 0:  24%|                                                                            | 119/497 [02:19<07:23,  1.17s/it, loss=0.151, v_num=75]Epoch 0:  24%|                                                                            | 119/497 [02:19<07:23,  1.17s/it, loss=0.141, v_num=75]Epoch 0:  24%|                                                                            | 120/497 [02:20<07:22,  1.17s/it, loss=0.141, v_num=75]Epoch 0:  24%|                                                                            | 120/497 [02:20<07:22,  1.17s/it, loss=0.129, v_num=75]Epoch 0:  24%|                                                                            | 121/497 [02:22<07:21,  1.17s/it, loss=0.129, v_num=75]Epoch 0:  24%|                                                                            | 121/497 [02:22<07:21,  1.17s/it, loss=0.123, v_num=75]Epoch 0:  25%|                                                                            | 122/497 [02:23<07:20,  1.17s/it, loss=0.123, v_num=75]Epoch 0:  25%|                                                                            | 122/497 [02:23<07:20,  1.17s/it, loss=0.131, v_num=75]Epoch 0:  25%|                                                                            | 123/497 [02:24<07:19,  1.17s/it, loss=0.131, v_num=75]Epoch 0:  25%|                                                                            | 123/497 [02:24<07:19,  1.17s/it, loss=0.126, v_num=75]Epoch 0:  25%|                                                                           | 124/497 [02:25<07:18,  1.17s/it, loss=0.126, v_num=75]Epoch 0:  25%|                                                                           | 124/497 [02:25<07:18,  1.17s/it, loss=0.128, v_num=75]Epoch 0:  25%|                                                                           | 125/497 [02:26<07:16,  1.17s/it, loss=0.128, v_num=75]Epoch 0:  25%|                                                                           | 125/497 [02:26<07:16,  1.17s/it, loss=0.126, v_num=75]Epoch 0:  25%|                                                                           | 126/497 [02:28<07:15,  1.17s/it, loss=0.126, v_num=75]Epoch 0:  25%|                                                                           | 126/497 [02:28<07:15,  1.17s/it, loss=0.121, v_num=75]Epoch 0:  26%|                                                                           | 127/497 [02:29<07:14,  1.18s/it, loss=0.121, v_num=75]Epoch 0:  26%|                                                                           | 127/497 [02:29<07:14,  1.18s/it, loss=0.116, v_num=75]Epoch 0:  26%|                                                                           | 128/497 [02:30<07:13,  1.18s/it, loss=0.116, v_num=75]Epoch 0:  26%|                                                                           | 128/497 [02:30<07:13,  1.18s/it, loss=0.123, v_num=75]Epoch 0:  26%|                                                                          | 129/497 [02:31<07:12,  1.18s/it, loss=0.123, v_num=75]Epoch 0:  26%|                                                                          | 129/497 [02:31<07:12,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  26%|                                                                          | 130/497 [02:32<07:11,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  26%|                                                                          | 130/497 [02:32<07:11,  1.18s/it, loss=0.126, v_num=75]Epoch 0:  26%|                                                                          | 131/497 [02:34<07:10,  1.18s/it, loss=0.126, v_num=75]Epoch 0:  26%|                                                                          | 131/497 [02:34<07:10,  1.18s/it, loss=0.127, v_num=75]Epoch 0:  27%|                                                                          | 132/497 [02:35<07:09,  1.18s/it, loss=0.127, v_num=75]Epoch 0:  27%|                                                                          | 132/497 [02:35<07:09,  1.18s/it, loss=0.126, v_num=75]Epoch 0:  27%|                                                                          | 133/497 [02:36<07:08,  1.18s/it, loss=0.126, v_num=75]Epoch 0:  27%|                                                                          | 133/497 [02:36<07:08,  1.18s/it, loss=0.127, v_num=75]Epoch 0:  27%|                                                                         | 134/497 [02:37<07:07,  1.18s/it, loss=0.127, v_num=75]Epoch 0:  27%|                                                                         | 134/497 [02:37<07:07,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  27%|                                                                         | 135/497 [02:38<07:05,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  27%|                                                                         | 135/497 [02:38<07:05,  1.18s/it, loss=0.123, v_num=75]Epoch 0:  27%|                                                                         | 136/497 [02:40<07:04,  1.18s/it, loss=0.123, v_num=75]Epoch 0:  27%|                                                                         | 136/497 [02:40<07:04,  1.18s/it, loss=0.121, v_num=75]Epoch 0:  28%|                                                                         | 137/497 [02:41<07:03,  1.18s/it, loss=0.121, v_num=75]Epoch 0:  28%|                                                                         | 137/497 [02:41<07:03,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  28%|                                                                         | 138/497 [02:42<07:02,  1.18s/it, loss=0.129, v_num=75]Epoch 0:  28%|                                                                         | 138/497 [02:42<07:02,  1.18s/it, loss=0.134, v_num=75]Epoch 0:  28%|                                                                        | 139/497 [02:43<07:01,  1.18s/it, loss=0.134, v_num=75]Epoch 0:  28%|                                                                        | 139/497 [02:43<07:01,  1.18s/it, loss=0.134, v_num=75]Epoch 0:  28%|                                                                        | 140/497 [02:44<07:00,  1.18s/it, loss=0.134, v_num=75]Epoch 0:  28%|                                                                        | 140/497 [02:44<07:00,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  28%|                                                                        | 141/497 [02:46<06:59,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  28%|                                                                         | 141/497 [02:46<06:59,  1.18s/it, loss=0.15, v_num=75]Epoch 0:  29%|                                                                        | 142/497 [02:47<06:58,  1.18s/it, loss=0.15, v_num=75]Epoch 0:  29%|                                                                        | 142/497 [02:47<06:58,  1.18s/it, loss=0.14, v_num=75]Epoch 0:  29%|                                                                        | 143/497 [02:48<06:57,  1.18s/it, loss=0.14, v_num=75]Epoch 0:  29%|                                                                        | 143/497 [02:48<06:57,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  29%|                                                                       | 144/497 [02:49<06:56,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  29%|                                                                       | 144/497 [02:49<06:56,  1.18s/it, loss=0.139, v_num=75]Epoch 0:  29%|                                                                       | 145/497 [02:50<06:54,  1.18s/it, loss=0.139, v_num=75]Epoch 0:  29%|                                                                       | 145/497 [02:50<06:54,  1.18s/it, loss=0.139, v_num=75]Epoch 0:  29%|                                                                       | 146/497 [02:52<06:53,  1.18s/it, loss=0.139, v_num=75]Epoch 0:  29%|                                                                       | 146/497 [02:52<06:53,  1.18s/it, loss=0.141, v_num=75]Epoch 0:  30%|                                                                       | 147/497 [02:53<06:52,  1.18s/it, loss=0.141, v_num=75]Epoch 0:  30%|                                                                       | 147/497 [02:53<06:52,  1.18s/it, loss=0.146, v_num=75]Epoch 0:  30%|                                                                       | 148/497 [02:54<06:51,  1.18s/it, loss=0.146, v_num=75]Epoch 0:  30%|                                                                       | 148/497 [02:54<06:51,  1.18s/it, loss=0.141, v_num=75]Epoch 0:  30%|                                                                      | 149/497 [02:55<06:50,  1.18s/it, loss=0.141, v_num=75]Epoch 0:  30%|                                                                      | 149/497 [02:55<06:50,  1.18s/it, loss=0.169, v_num=75]Epoch 0:  30%|                                                                      | 150/497 [02:56<06:49,  1.18s/it, loss=0.169, v_num=75]Epoch 0:  30%|                                                                      | 150/497 [02:56<06:49,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  30%|                                                                      | 151/497 [02:58<06:48,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  30%|                                                                      | 151/497 [02:58<06:48,  1.18s/it, loss=0.172, v_num=75]Epoch 0:  31%|                                                                      | 152/497 [02:59<06:47,  1.18s/it, loss=0.172, v_num=75]Epoch 0:  31%|                                                                      | 152/497 [02:59<06:47,  1.18s/it, loss=0.17, v_num=75]Epoch 0:  31%|                                                                      | 153/497 [03:00<06:46,  1.18s/it, loss=0.17, v_num=75]Epoch 0:  31%|                                                                      | 153/497 [03:00<06:46,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  31%|                                                                     | 154/497 [03:01<06:44,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  31%|                                                                     | 154/497 [03:01<06:44,  1.18s/it, loss=0.175, v_num=75]Epoch 0:  31%|                                                                     | 155/497 [03:03<06:43,  1.18s/it, loss=0.175, v_num=75]Epoch 0:  31%|                                                                     | 155/497 [03:03<06:43,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  31%|                                                                     | 156/497 [03:04<06:42,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  31%|                                                                      | 156/497 [03:04<06:42,  1.18s/it, loss=0.18, v_num=75]Epoch 0:  32%|                                                                     | 157/497 [03:05<06:41,  1.18s/it, loss=0.18, v_num=75]Epoch 0:  32%|                                                                     | 157/497 [03:05<06:41,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  32%|                                                                     | 158/497 [03:06<06:40,  1.18s/it, loss=0.173, v_num=75]Epoch 0:  32%|                                                                     | 158/497 [03:06<06:40,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  32%|                                                                    | 159/497 [03:07<06:39,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  32%|                                                                    | 159/497 [03:07<06:39,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  32%|                                                                    | 160/497 [03:09<06:38,  1.18s/it, loss=0.177, v_num=75]Epoch 0:  32%|                                                                     | 160/497 [03:09<06:38,  1.18s/it, loss=0.17, v_num=75]Epoch 0:  32%|                                                                     | 161/497 [03:10<06:37,  1.18s/it, loss=0.17, v_num=75]Epoch 0:  32%|                                                                    | 161/497 [03:10<06:37,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                    | 162/497 [03:11<06:35,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                    | 162/497 [03:11<06:35,  1.18s/it, loss=0.162, v_num=75]Epoch 0:  33%|                                                                    | 163/497 [03:12<06:34,  1.18s/it, loss=0.162, v_num=75]Epoch 0:  33%|                                                                    | 163/497 [03:12<06:34,  1.18s/it, loss=0.166, v_num=75]Epoch 0:  33%|                                                                   | 164/497 [03:13<06:33,  1.18s/it, loss=0.166, v_num=75]Epoch 0:  33%|                                                                   | 164/497 [03:13<06:33,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                   | 165/497 [03:15<06:32,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                   | 165/497 [03:15<06:32,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                   | 166/497 [03:16<06:31,  1.18s/it, loss=0.165, v_num=75]Epoch 0:  33%|                                                                   | 166/497 [03:16<06:31,  1.18s/it, loss=0.164, v_num=75]Epoch 0:  34%|                                                                   | 167/497 [03:17<06:30,  1.18s/it, loss=0.164, v_num=75]Epoch 0:  34%|                                                                   | 167/497 [03:17<06:30,  1.18s/it, loss=0.169, v_num=75]Epoch 0:  34%|                                                                  | 168/497 [03:18<06:29,  1.18s/it, loss=0.169, v_num=75]Epoch 0:  34%|                                                                  | 168/497 [03:18<06:29,  1.18s/it, loss=0.164, v_num=75]Epoch 0:  34%|                                                                  | 169/497 [03:19<06:27,  1.18s/it, loss=0.164, v_num=75]Epoch 0:  34%|                                                                  | 169/497 [03:19<06:27,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  34%|                                                                  | 170/497 [03:21<06:26,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  34%|                                                                  | 170/497 [03:21<06:26,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  34%|                                                                  | 171/497 [03:22<06:25,  1.18s/it, loss=0.142, v_num=75]Epoch 0:  34%|                                                                  | 171/497 [03:22<06:25,  1.18s/it, loss=0.145, v_num=75]Epoch 0:  35%|                                                                  | 172/497 [03:23<06:24,  1.18s/it, loss=0.145, v_num=75]Epoch 0:  35%|                                                                  | 172/497 [03:23<06:24,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  35%|                                                                 | 173/497 [03:24<06:23,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  35%|                                                                 | 173/497 [03:24<06:23,  1.18s/it, loss=0.143, v_num=75]Epoch 0:  35%|                                                                 | 174/497 [03:25<06:22,  1.18s/it, loss=0.143, v_num=75]Epoch 0:  35%|                                                                 | 174/497 [03:25<06:22,  1.18s/it, loss=0.146, v_num=75]Epoch 0:  35%|                                                                 | 175/497 [03:27<06:21,  1.18s/it, loss=0.146, v_num=75]Epoch 0:  35%|                                                                 | 175/497 [03:27<06:21,  1.18s/it, loss=0.145, v_num=75]Epoch 0:  35%|                                                                 | 176/497 [03:28<06:19,  1.18s/it, loss=0.145, v_num=75]Epoch 0:  35%|                                                                 | 176/497 [03:28<06:19,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  36%|                                                                 | 177/497 [03:29<06:18,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  36%|                                                                 | 177/497 [03:29<06:18,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  36%|                                                                | 178/497 [03:30<06:17,  1.18s/it, loss=0.144, v_num=75]Epoch 0:  36%|                                                                | 178/497 [03:30<06:17,  1.18s/it, loss=0.138, v_num=75]Epoch 0:  36%|                                                                | 179/497 [03:31<06:16,  1.18s/it, loss=0.138, v_num=75]Epoch 0:  36%|                                                                | 179/497 [03:31<06:16,  1.18s/it, loss=0.136, v_num=75]Epoch 0:  36%|                                                                | 180/497 [03:33<06:15,  1.18s/it, loss=0.136, v_num=75]Epoch 0:  36%|                                                                | 180/497 [03:33<06:15,  1.18s/it, loss=0.149, v_num=75]Epoch 0:  36%|                                                                | 181/497 [03:34<06:14,  1.18s/it, loss=0.149, v_num=75]Epoch 0:  36%|                                                                | 181/497 [03:34<06:14,  1.18s/it, loss=0.152, v_num=75]Epoch 0:  37%|                                                                | 182/497 [03:35<06:13,  1.18s/it, loss=0.152, v_num=75]Epoch 0:  37%|                                                                | 182/497 [03:35<06:13,  1.18s/it, loss=0.153, v_num=75]Epoch 0:  37%|                                                               | 183/497 [03:36<06:11,  1.18s/it, loss=0.153, v_num=75]Epoch 0:  37%|                                                               | 183/497 [03:36<06:11,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  37%|                                                               | 184/497 [03:37<06:10,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  37%|                                                               | 184/497 [03:37<06:10,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  37%|                                                               | 185/497 [03:39<06:09,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  37%|                                                               | 185/497 [03:39<06:09,  1.18s/it, loss=0.154, v_num=75]Epoch 0:  37%|                                                               | 186/497 [03:40<06:08,  1.18s/it, loss=0.154, v_num=75]Epoch 0:  37%|                                                               | 186/497 [03:40<06:08,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  38%|                                                               | 187/497 [03:41<06:07,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  38%|                                                               | 187/497 [03:41<06:07,  1.18s/it, loss=0.147, v_num=75]Epoch 0:  38%|                                                              | 188/497 [03:42<06:06,  1.18s/it, loss=0.147, v_num=75]Epoch 0:  38%|                                                              | 188/497 [03:42<06:06,  1.18s/it, loss=0.155, v_num=75]Epoch 0:  38%|                                                              | 189/497 [03:43<06:05,  1.19s/it, loss=0.155, v_num=75]Epoch 0:  38%|                                                              | 189/497 [03:43<06:05,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  38%|                                                              | 190/497 [03:45<06:03,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  38%|                                                              | 190/497 [03:45<06:03,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  38%|                                                              | 191/497 [03:46<06:02,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  38%|                                                              | 191/497 [03:46<06:02,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  39%|                                                              | 192/497 [03:47<06:01,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  39%|                                                              | 192/497 [03:47<06:01,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  39%|                                                             | 193/497 [03:48<06:00,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  39%|                                                             | 193/497 [03:48<06:00,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  39%|                                                             | 194/497 [03:49<05:59,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  39%|                                                             | 194/497 [03:50<05:59,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  39%|                                                             | 195/497 [03:51<05:58,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  39%|                                                             | 195/497 [03:51<05:58,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  39%|                                                             | 196/497 [03:52<05:56,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  39%|                                                             | 196/497 [03:52<05:56,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  40%|                                                             | 197/497 [03:53<05:55,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  40%|                                                             | 197/497 [03:53<05:55,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  40%|                                                            | 198/497 [03:54<05:54,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  40%|                                                            | 198/497 [03:54<05:54,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  40%|                                                            | 199/497 [03:56<05:53,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  40%|                                                            | 199/497 [03:56<05:53,  1.19s/it, loss=0.155, v_num=75]Epoch 0:  40%|                                                            | 200/497 [03:57<05:52,  1.19s/it, loss=0.155, v_num=75]Epoch 0:  40%|                                                            | 200/497 [03:57<05:52,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  40%|                                                            | 201/497 [03:58<05:51,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  40%|                                                            | 201/497 [03:58<05:51,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  41%|                                                            | 202/497 [03:59<05:49,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  41%|                                                            | 202/497 [03:59<05:49,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  41%|                                                           | 203/497 [04:00<05:48,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  41%|                                                            | 203/497 [04:00<05:48,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  41%|                                                            | 204/497 [04:02<05:47,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  41%|                                                           | 204/497 [04:02<05:47,  1.19s/it, loss=0.142, v_num=75]Epoch 0:  41%|                                                           | 205/497 [04:03<05:46,  1.19s/it, loss=0.142, v_num=75]Epoch 0:  41%|                                                           | 205/497 [04:03<05:46,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  41%|                                                           | 206/497 [04:04<05:45,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  41%|                                                           | 206/497 [04:04<05:45,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  42%|                                                           | 207/497 [04:05<05:44,  1.19s/it, loss=0.153, v_num=75]Epoch 0:  42%|                                                           | 207/497 [04:05<05:44,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  42%|                                                          | 208/497 [04:06<05:42,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  42%|                                                          | 208/497 [04:06<05:42,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  42%|                                                          | 209/497 [04:08<05:41,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  42%|                                                          | 209/497 [04:08<05:41,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  42%|                                                          | 210/497 [04:09<05:40,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  42%|                                                          | 210/497 [04:09<05:40,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  42%|                                                          | 211/497 [04:10<05:39,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  42%|                                                          | 211/497 [04:10<05:39,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  43%|                                                          | 212/497 [04:11<05:38,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  43%|                                                          | 212/497 [04:11<05:38,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  43%|                                                         | 213/497 [04:12<05:37,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  43%|                                                         | 213/497 [04:12<05:37,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  43%|                                                         | 214/497 [04:14<05:35,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  43%|                                                         | 214/497 [04:14<05:35,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  43%|                                                         | 215/497 [04:15<05:34,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  43%|                                                         | 215/497 [04:15<05:34,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  43%|                                                         | 216/497 [04:16<05:33,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  43%|                                                         | 216/497 [04:16<05:33,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  44%|                                                         | 217/497 [04:17<05:32,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  44%|                                                         | 217/497 [04:17<05:32,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  44%|                                                         | 218/497 [04:18<05:31,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  44%|                                                        | 218/497 [04:18<05:31,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  44%|                                                        | 219/497 [04:20<05:30,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  44%|                                                        | 219/497 [04:20<05:30,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  44%|                                                        | 220/497 [04:21<05:28,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  44%|                                                        | 220/497 [04:21<05:28,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  44%|                                                        | 221/497 [04:22<05:27,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  44%|                                                        | 221/497 [04:22<05:27,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  45%|                                                        | 222/497 [04:23<05:26,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  45%|                                                        | 222/497 [04:23<05:26,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  45%|                                                       | 223/497 [04:24<05:25,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  45%|                                                       | 223/497 [04:24<05:25,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  45%|                                                       | 224/497 [04:26<05:24,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  45%|                                                       | 224/497 [04:26<05:24,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  45%|                                                       | 225/497 [04:27<05:23,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  45%|                                                       | 225/497 [04:27<05:23,  1.19s/it, loss=0.113, v_num=75]Epoch 0:  45%|                                                       | 226/497 [04:28<05:21,  1.19s/it, loss=0.113, v_num=75]Epoch 0:  45%|                                                       | 226/497 [04:28<05:21,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  46%|                                                      | 227/497 [04:29<05:20,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  46%|                                                      | 227/497 [04:29<05:20,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  46%|                                                      | 228/497 [04:30<05:19,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  46%|                                                      | 228/497 [04:30<05:19,  1.19s/it, loss=0.103, v_num=75]Epoch 0:  46%|                                                      | 229/497 [04:32<05:18,  1.19s/it, loss=0.103, v_num=75]Epoch 0:  46%|                                                      | 229/497 [04:32<05:18,  1.19s/it, loss=0.102, v_num=75]Epoch 0:  46%|                                                      | 230/497 [04:33<05:17,  1.19s/it, loss=0.102, v_num=75]Epoch 0:  46%|                                                     | 230/497 [04:33<05:17,  1.19s/it, loss=0.0979, v_num=75]Epoch 0:  46%|                                                     | 231/497 [04:34<05:16,  1.19s/it, loss=0.0979, v_num=75]Epoch 0:  46%|                                                     | 231/497 [04:34<05:16,  1.19s/it, loss=0.0952, v_num=75]Epoch 0:  47%|                                                     | 232/497 [04:35<05:14,  1.19s/it, loss=0.0952, v_num=75]Epoch 0:  47%|                                                     | 232/497 [04:35<05:14,  1.19s/it, loss=0.096, v_num=75]Epoch 0:  47%|                                                     | 233/497 [04:36<05:13,  1.19s/it, loss=0.096, v_num=75]Epoch 0:  47%|                                                      | 233/497 [04:36<05:13,  1.19s/it, loss=0.1, v_num=75]Epoch 0:  47%|                                                      | 234/497 [04:38<05:12,  1.19s/it, loss=0.1, v_num=75]Epoch 0:  47%|                                                     | 234/497 [04:38<05:12,  1.19s/it, loss=0.101, v_num=75]Epoch 0:  47%|                                                     | 235/497 [04:39<05:11,  1.19s/it, loss=0.101, v_num=75]Epoch 0:  47%|                                                    | 235/497 [04:39<05:11,  1.19s/it, loss=0.0976, v_num=75]Epoch 0:  47%|                                                    | 236/497 [04:40<05:10,  1.19s/it, loss=0.0976, v_num=75]Epoch 0:  47%|                                                    | 236/497 [04:40<05:10,  1.19s/it, loss=0.0984, v_num=75]Epoch 0:  48%|                                                    | 237/497 [04:41<05:09,  1.19s/it, loss=0.0984, v_num=75]Epoch 0:  48%|                                                    | 237/497 [04:41<05:09,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  48%|                                                    | 238/497 [04:42<05:07,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  48%|                                                    | 238/497 [04:42<05:07,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  48%|                                                    | 239/497 [04:44<05:06,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  48%|                                                     | 239/497 [04:44<05:06,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  48%|                                                    | 240/497 [04:45<05:05,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  48%|                                                    | 240/497 [04:45<05:05,  1.19s/it, loss=0.109, v_num=75]Epoch 0:  48%|                                                    | 241/497 [04:46<05:04,  1.19s/it, loss=0.109, v_num=75]Epoch 0:  48%|                                                    | 241/497 [04:46<05:04,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  49%|                                                   | 242/497 [04:47<05:03,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  49%|                                                   | 242/497 [04:47<05:03,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  49%|                                                   | 243/497 [04:48<05:02,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  49%|                                                    | 243/497 [04:48<05:02,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  49%|                                                    | 244/497 [04:50<05:00,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  49%|                                                   | 244/497 [04:50<05:00,  1.19s/it, loss=0.108, v_num=75]Epoch 0:  49%|                                                   | 245/497 [04:51<04:59,  1.19s/it, loss=0.108, v_num=75]Epoch 0:  49%|                                                   | 245/497 [04:51<04:59,  1.19s/it, loss=0.108, v_num=75]Epoch 0:  49%|                                                   | 246/497 [04:52<04:58,  1.19s/it, loss=0.108, v_num=75]Epoch 0:  49%|                                                   | 246/497 [04:52<04:58,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  50%|                                                  | 247/497 [04:53<04:57,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  50%|                                                  | 247/497 [04:53<04:57,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  50%|                                                  | 248/497 [04:54<04:56,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  50%|                                                  | 248/497 [04:54<04:56,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  50%|                                                  | 249/497 [04:56<04:54,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  50%|                                                  | 249/497 [04:56<04:54,  1.19s/it, loss=0.136, v_num=75]Epoch 0:  50%|                                                  | 250/497 [04:57<04:53,  1.19s/it, loss=0.136, v_num=75]Epoch 0:  50%|                                                  | 250/497 [04:57<04:53,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                  | 251/497 [04:58<04:52,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                  | 251/497 [04:58<04:52,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                 | 252/497 [04:59<04:51,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                 | 252/497 [04:59<04:51,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                 | 253/497 [05:01<04:50,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  51%|                                                 | 253/497 [05:01<04:50,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  51%|                                                 | 254/497 [05:02<04:49,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  51%|                                                 | 254/497 [05:02<04:49,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  51%|                                                 | 255/497 [05:03<04:47,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  51%|                                                 | 255/497 [05:03<04:47,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  52%|                                                 | 256/497 [05:04<04:46,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  52%|                                                 | 256/497 [05:04<04:46,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  52%|                                                | 257/497 [05:05<04:45,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  52%|                                                 | 257/497 [05:05<04:45,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  52%|                                                 | 258/497 [05:07<04:44,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  52%|                                                | 258/497 [05:07<04:44,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  52%|                                                | 259/497 [05:08<04:43,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  52%|                                                | 259/497 [05:08<04:43,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  52%|                                                | 260/497 [05:09<04:42,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  52%|                                                | 260/497 [05:09<04:42,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  53%|                                                | 261/497 [05:10<04:40,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  53%|                                                | 261/497 [05:10<04:40,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  53%|                                               | 262/497 [05:11<04:39,  1.19s/it, loss=0.145, v_num=75]Epoch 0:  53%|                                               | 262/497 [05:11<04:39,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  53%|                                               | 263/497 [05:13<04:38,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  53%|                                               | 263/497 [05:13<04:38,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  53%|                                               | 264/497 [05:14<04:37,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  53%|                                               | 264/497 [05:14<04:37,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  53%|                                               | 265/497 [05:15<04:36,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  53%|                                               | 265/497 [05:15<04:36,  1.19s/it, loss=0.162, v_num=75]Epoch 0:  54%|                                               | 266/497 [05:16<04:34,  1.19s/it, loss=0.162, v_num=75]Epoch 0:  54%|                                               | 266/497 [05:16<04:34,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  54%|                                              | 267/497 [05:17<04:33,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  54%|                                              | 267/497 [05:17<04:33,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  54%|                                              | 268/497 [05:19<04:32,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  54%|                                              | 268/497 [05:19<04:32,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  54%|                                              | 269/497 [05:20<04:31,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  54%|                                              | 269/497 [05:20<04:31,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  54%|                                              | 270/497 [05:21<04:30,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  54%|                                              | 270/497 [05:21<04:30,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  55%|                                              | 271/497 [05:22<04:29,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  55%|                                              | 271/497 [05:22<04:29,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  55%|                                             | 272/497 [05:23<04:27,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  55%|                                             | 272/497 [05:23<04:27,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  55%|                                             | 273/497 [05:25<04:26,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  55%|                                             | 273/497 [05:25<04:26,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  55%|                                             | 274/497 [05:26<04:25,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  55%|                                             | 274/497 [05:26<04:25,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  55%|                                             | 275/497 [05:27<04:24,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  55%|                                             | 275/497 [05:27<04:24,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  56%|                                             | 276/497 [05:28<04:23,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  56%|                                             | 276/497 [05:28<04:23,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  56%|                                            | 277/497 [05:29<04:22,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  56%|                                             | 277/497 [05:29<04:22,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  56%|                                             | 278/497 [05:31<04:20,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  56%|                                             | 278/497 [05:31<04:20,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  56%|                                            | 279/497 [05:32<04:19,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  56%|                                            | 279/497 [05:32<04:19,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  56%|                                            | 280/497 [05:33<04:18,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  56%|                                            | 280/497 [05:33<04:18,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  57%|                                            | 281/497 [05:34<04:17,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  57%|                                            | 281/497 [05:34<04:17,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  57%|                                           | 282/497 [05:35<04:16,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  57%|                                           | 282/497 [05:35<04:16,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  57%|                                           | 283/497 [05:37<04:14,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  57%|                                            | 283/497 [05:37<04:14,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  57%|                                           | 284/497 [05:38<04:13,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  57%|                                           | 284/497 [05:38<04:13,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  57%|                                           | 285/497 [05:39<04:12,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  57%|                                           | 285/497 [05:39<04:12,  1.19s/it, loss=0.107, v_num=75]Epoch 0:  58%|                                           | 286/497 [05:40<04:11,  1.19s/it, loss=0.107, v_num=75]Epoch 0:  58%|                                           | 286/497 [05:40<04:11,  1.19s/it, loss=0.107, v_num=75]Epoch 0:  58%|                                          | 287/497 [05:41<04:10,  1.19s/it, loss=0.107, v_num=75]Epoch 0:  58%|                                          | 287/497 [05:41<04:10,  1.19s/it, loss=0.109, v_num=75]Epoch 0:  58%|                                          | 288/497 [05:43<04:09,  1.19s/it, loss=0.109, v_num=75]Epoch 0:  58%|                                          | 288/497 [05:43<04:09,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  58%|                                          | 289/497 [05:44<04:07,  1.19s/it, loss=0.111, v_num=75]Epoch 0:  58%|                                          | 289/497 [05:44<04:07,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  58%|                                          | 290/497 [05:45<04:06,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  58%|                                          | 290/497 [05:45<04:06,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  59%|                                         | 291/497 [05:46<04:05,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  59%|                                         | 291/497 [05:46<04:05,  1.19s/it, loss=0.118, v_num=75]Epoch 0:  59%|                                         | 292/497 [05:47<04:04,  1.19s/it, loss=0.118, v_num=75]Epoch 0:  59%|                                         | 292/497 [05:47<04:04,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  59%|                                         | 293/497 [05:49<04:03,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  59%|                                         | 293/497 [05:49<04:03,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  59%|                                         | 294/497 [05:50<04:01,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  59%|                                         | 294/497 [05:50<04:01,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  59%|                                         | 295/497 [05:51<04:00,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  59%|                                         | 295/497 [05:51<04:00,  1.19s/it, loss=0.105, v_num=75]Epoch 0:  60%|                                        | 296/497 [05:52<03:59,  1.19s/it, loss=0.105, v_num=75]Epoch 0:  60%|                                        | 296/497 [05:52<03:59,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  60%|                                        | 297/497 [05:53<03:58,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  60%|                                         | 297/497 [05:53<03:58,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  60%|                                        | 298/497 [05:55<03:57,  1.19s/it, loss=0.11, v_num=75]Epoch 0:  60%|                                        | 298/497 [05:55<03:57,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  60%|                                        | 299/497 [05:56<03:56,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  60%|                                        | 299/497 [05:56<03:56,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  60%|                                        | 300/497 [05:57<03:54,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  60%|                                        | 300/497 [05:57<03:54,  1.19s/it, loss=0.127, v_num=75]Epoch 0:  61%|                                       | 301/497 [05:58<03:53,  1.19s/it, loss=0.127, v_num=75]Epoch 0:  61%|                                       | 301/497 [05:58<03:53,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  61%|                                       | 302/497 [06:00<03:52,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  61%|                                       | 302/497 [06:00<03:52,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  61%|                                       | 303/497 [06:01<03:51,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  61%|                                       | 303/497 [06:01<03:51,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  61%|                                       | 304/497 [06:02<03:50,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  61%|                                       | 304/497 [06:02<03:50,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  61%|                                       | 305/497 [06:03<03:48,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  61%|                                       | 305/497 [06:03<03:48,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  62%|                                      | 306/497 [06:04<03:47,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  62%|                                      | 306/497 [06:04<03:47,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  62%|                                      | 307/497 [06:06<03:46,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  62%|                                      | 307/497 [06:06<03:46,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  62%|                                      | 308/497 [06:07<03:45,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  62%|                                      | 308/497 [06:07<03:45,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  62%|                                      | 309/497 [06:08<03:44,  1.19s/it, loss=0.124, v_num=75]Epoch 0:  62%|                                      | 309/497 [06:08<03:44,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  62%|                                      | 310/497 [06:09<03:42,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  62%|                                      | 310/497 [06:09<03:42,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  63%|                                     | 311/497 [06:10<03:41,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  63%|                                      | 311/497 [06:10<03:41,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  63%|                                      | 312/497 [06:12<03:40,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  63%|                                     | 312/497 [06:12<03:40,  1.19s/it, loss=0.118, v_num=75]Epoch 0:  63%|                                     | 313/497 [06:13<03:39,  1.19s/it, loss=0.118, v_num=75]Epoch 0:  63%|                                     | 313/497 [06:13<03:39,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  63%|                                     | 314/497 [06:14<03:38,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  63%|                                     | 314/497 [06:14<03:38,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  63%|                                     | 315/497 [06:15<03:37,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  63%|                                     | 315/497 [06:15<03:37,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  64%|                                    | 316/497 [06:16<03:35,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  64%|                                     | 316/497 [06:16<03:35,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  64%|                                     | 317/497 [06:18<03:34,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  64%|                                    | 317/497 [06:18<03:34,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  64%|                                    | 318/497 [06:19<03:33,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  64%|                                    | 318/497 [06:19<03:33,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  64%|                                    | 319/497 [06:20<03:32,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  64%|                                    | 319/497 [06:20<03:32,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  64%|                                    | 320/497 [06:21<03:31,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  64%|                                    | 320/497 [06:21<03:31,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  65%|                                    | 321/497 [06:22<03:29,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  65%|                                   | 321/497 [06:22<03:29,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  65%|                                   | 322/497 [06:24<03:28,  1.19s/it, loss=0.143, v_num=75]Epoch 0:  65%|                                   | 322/497 [06:24<03:28,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  65%|                                   | 323/497 [06:25<03:27,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  65%|                                   | 323/497 [06:25<03:27,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  65%|                                   | 324/497 [06:26<03:26,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  65%|                                   | 324/497 [06:26<03:26,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  65%|                                   | 325/497 [06:27<03:25,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  65%|                                   | 325/497 [06:27<03:25,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 326/497 [06:28<03:24,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 326/497 [06:28<03:24,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  66%|                                  | 327/497 [06:30<03:22,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  66%|                                  | 327/497 [06:30<03:22,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 328/497 [06:31<03:21,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 328/497 [06:31<03:21,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 329/497 [06:32<03:20,  1.19s/it, loss=0.157, v_num=75]Epoch 0:  66%|                                  | 329/497 [06:32<03:20,  1.19s/it, loss=0.155, v_num=75]Epoch 0:  66%|                                  | 330/497 [06:33<03:19,  1.19s/it, loss=0.155, v_num=75]Epoch 0:  66%|                                  | 330/497 [06:33<03:19,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 331/497 [06:34<03:18,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 331/497 [06:34<03:18,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 332/497 [06:36<03:16,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 332/497 [06:36<03:16,  1.19s/it, loss=0.159, v_num=75]Epoch 0:  67%|                                 | 333/497 [06:37<03:15,  1.19s/it, loss=0.159, v_num=75]Epoch 0:  67%|                                 | 333/497 [06:37<03:15,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 334/497 [06:38<03:14,  1.19s/it, loss=0.158, v_num=75]Epoch 0:  67%|                                 | 334/497 [06:38<03:14,  1.19s/it, loss=0.16, v_num=75]Epoch 0:  67%|                                 | 335/497 [06:39<03:13,  1.19s/it, loss=0.16, v_num=75]Epoch 0:  67%|                                 | 335/497 [06:39<03:13,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  68%|                                | 336/497 [06:40<03:12,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  68%|                                | 336/497 [06:40<03:12,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  68%|                                | 337/497 [06:42<03:10,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  68%|                                | 337/497 [06:42<03:10,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  68%|                                | 338/497 [06:43<03:09,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  68%|                                | 338/497 [06:43<03:09,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  68%|                                | 339/497 [06:44<03:08,  1.19s/it, loss=0.156, v_num=75]Epoch 0:  68%|                                | 339/497 [06:44<03:08,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  68%|                                | 340/497 [06:45<03:07,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  68%|                                | 340/497 [06:45<03:07,  1.19s/it, loss=0.134, v_num=75]Epoch 0:  69%|                               | 341/497 [06:46<03:06,  1.19s/it, loss=0.134, v_num=75]Epoch 0:  69%|                               | 341/497 [06:46<03:06,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  69%|                               | 342/497 [06:48<03:04,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  69%|                               | 342/497 [06:48<03:04,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  69%|                               | 343/497 [06:49<03:03,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  69%|                               | 343/497 [06:49<03:03,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  69%|                               | 344/497 [06:50<03:02,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  69%|                               | 344/497 [06:50<03:02,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  69%|                               | 345/497 [06:51<03:01,  1.19s/it, loss=0.117, v_num=75]Epoch 0:  69%|                               | 345/497 [06:51<03:01,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  70%|                              | 346/497 [06:52<03:00,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  70%|                              | 346/497 [06:52<03:00,  1.19s/it, loss=0.116, v_num=75]Epoch 0:  70%|                              | 347/497 [06:54<02:59,  1.19s/it, loss=0.116, v_num=75]Epoch 0:  70%|                              | 347/497 [06:54<02:59,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  70%|                              | 348/497 [06:55<02:57,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  70%|                              | 348/497 [06:55<02:57,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  70%|                              | 349/497 [06:56<02:56,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  70%|                              | 349/497 [06:56<02:56,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  70%|                             | 350/497 [06:57<02:55,  1.19s/it, loss=0.112, v_num=75]Epoch 0:  70%|                             | 350/497 [06:57<02:55,  1.19s/it, loss=0.113, v_num=75]Epoch 0:  71%|                             | 351/497 [06:58<02:54,  1.19s/it, loss=0.113, v_num=75]Epoch 0:  71%|                             | 351/497 [06:58<02:54,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  71%|                             | 352/497 [07:00<02:53,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  71%|                             | 352/497 [07:00<02:53,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  71%|                             | 353/497 [07:01<02:51,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  71%|                             | 353/497 [07:01<02:51,  1.19s/it, loss=0.142, v_num=75]Epoch 0:  71%|                             | 354/497 [07:02<02:50,  1.19s/it, loss=0.142, v_num=75]Epoch 0:  71%|                             | 354/497 [07:02<02:50,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  71%|                            | 355/497 [07:03<02:49,  1.19s/it, loss=0.146, v_num=75]Epoch 0:  71%|                            | 355/497 [07:03<02:49,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  72%|                            | 356/497 [07:04<02:48,  1.19s/it, loss=0.149, v_num=75]Epoch 0:  72%|                             | 356/497 [07:04<02:48,  1.19s/it, loss=0.15, v_num=75]Epoch 0:  72%|                            | 357/497 [07:06<02:47,  1.19s/it, loss=0.15, v_num=75]Epoch 0:  72%|                            | 357/497 [07:06<02:47,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  72%|                            | 358/497 [07:07<02:45,  1.19s/it, loss=0.152, v_num=75]Epoch 0:  72%|                            | 358/497 [07:07<02:45,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  72%|                            | 359/497 [07:08<02:44,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  72%|                            | 359/497 [07:08<02:44,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  72%|                           | 360/497 [07:09<02:43,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  72%|                           | 360/497 [07:09<02:43,  1.19s/it, loss=0.137, v_num=75]Epoch 0:  73%|                           | 361/497 [07:10<02:42,  1.19s/it, loss=0.137, v_num=75]Epoch 0:  73%|                           | 361/497 [07:10<02:42,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  73%|                           | 362/497 [07:12<02:41,  1.19s/it, loss=0.139, v_num=75]Epoch 0:  73%|                           | 362/497 [07:12<02:41,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  73%|                           | 363/497 [07:13<02:39,  1.19s/it, loss=0.138, v_num=75]Epoch 0:  73%|                           | 363/497 [07:13<02:39,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  73%|                           | 364/497 [07:14<02:38,  1.19s/it, loss=0.14, v_num=75]Epoch 0:  73%|                           | 364/497 [07:14<02:38,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  73%|                          | 365/497 [07:15<02:37,  1.19s/it, loss=0.147, v_num=75]Epoch 0:  73%|                          | 365/497 [07:15<02:37,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  74%|                          | 366/497 [07:17<02:36,  1.19s/it, loss=0.144, v_num=75]Epoch 0:  74%|                          | 366/497 [07:17<02:36,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  74%|                          | 367/497 [07:18<02:35,  1.19s/it, loss=0.148, v_num=75]Epoch 0:  74%|                          | 367/497 [07:18<02:35,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  74%|                          | 368/497 [07:19<02:34,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  74%|                          | 368/497 [07:19<02:34,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  74%|                          | 369/497 [07:20<02:32,  1.19s/it, loss=0.151, v_num=75]Epoch 0:  74%|                          | 369/497 [07:20<02:32,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  74%|                         | 370/497 [07:21<02:31,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  74%|                         | 370/497 [07:21<02:31,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  75%|                         | 371/497 [07:23<02:30,  1.19s/it, loss=0.154, v_num=75]Epoch 0:  75%|                         | 371/497 [07:23<02:30,  1.19s/it, loss=0.162, v_num=75]Epoch 0:  75%|                         | 372/497 [07:24<02:29,  1.19s/it, loss=0.162, v_num=75]Epoch 0:  75%|                         | 372/497 [07:24<02:29,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  75%|                         | 373/497 [07:25<02:28,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  75%|                         | 373/497 [07:25<02:28,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  75%|                         | 374/497 [07:26<02:26,  1.19s/it, loss=0.141, v_num=75]Epoch 0:  75%|                         | 374/497 [07:26<02:26,  1.19s/it, loss=0.136, v_num=75]Epoch 0:  75%|                        | 375/497 [07:27<02:25,  1.19s/it, loss=0.136, v_num=75]Epoch 0:  75%|                        | 375/497 [07:27<02:25,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  76%|                        | 376/497 [07:29<02:24,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  76%|                        | 376/497 [07:29<02:24,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  76%|                        | 377/497 [07:30<02:23,  1.19s/it, loss=0.129, v_num=75]Epoch 0:  76%|                        | 377/497 [07:30<02:23,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  76%|                        | 378/497 [07:31<02:22,  1.19s/it, loss=0.126, v_num=75]Epoch 0:  76%|                        | 378/497 [07:31<02:22,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  76%|                        | 379/497 [07:32<02:20,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  76%|                        | 379/497 [07:32<02:20,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  76%|                       | 380/497 [07:33<02:19,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  76%|                       | 380/497 [07:33<02:19,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  77%|                       | 381/497 [07:35<02:18,  1.19s/it, loss=0.119, v_num=75]Epoch 0:  77%|                       | 381/497 [07:35<02:18,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  77%|                       | 382/497 [07:36<02:17,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  77%|                       | 382/497 [07:36<02:17,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  77%|                       | 383/497 [07:37<02:16,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  77%|                       | 383/497 [07:37<02:16,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  77%|                       | 384/497 [07:38<02:14,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  77%|                       | 384/497 [07:38<02:14,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  77%|                      | 385/497 [07:39<02:13,  1.19s/it, loss=0.135, v_num=75]Epoch 0:  77%|                       | 385/497 [07:39<02:13,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  78%|                      | 386/497 [07:41<02:12,  1.19s/it, loss=0.13, v_num=75]Epoch 0:  78%|                      | 386/497 [07:41<02:12,  1.19s/it, loss=0.137, v_num=75]Epoch 0:  78%|                      | 387/497 [07:42<02:11,  1.19s/it, loss=0.137, v_num=75]Epoch 0:  78%|                      | 387/497 [07:42<02:11,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  78%|                      | 388/497 [07:43<02:10,  1.19s/it, loss=0.133, v_num=75]Epoch 0:  78%|                      | 388/497 [07:43<02:10,  1.19s/it, loss=0.132, v_num=75]Epoch 0:  78%|                      | 389/497 [07:44<02:09,  1.19s/it, loss=0.132, v_num=75]Epoch 0:  78%|                      | 389/497 [07:44<02:09,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  78%|                     | 390/497 [07:45<02:07,  1.19s/it, loss=0.131, v_num=75]Epoch 0:  78%|                     | 390/497 [07:45<02:07,  1.19s/it, loss=0.127, v_num=75]Epoch 0:  79%|                     | 391/497 [07:47<02:06,  1.19s/it, loss=0.127, v_num=75]Epoch 0:  79%|                     | 391/497 [07:47<02:06,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  79%|                     | 392/497 [07:48<02:05,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  79%|                     | 392/497 [07:48<02:05,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  79%|                     | 393/497 [07:49<02:04,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  79%|                     | 393/497 [07:49<02:04,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  79%|                     | 394/497 [07:50<02:03,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  79%|                     | 394/497 [07:50<02:03,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  79%|                    | 395/497 [07:51<02:01,  1.19s/it, loss=0.114, v_num=75]Epoch 0:  79%|                    | 395/497 [07:51<02:01,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  80%|                    | 396/497 [07:53<02:00,  1.19s/it, loss=0.115, v_num=75]Epoch 0:  80%|                    | 396/497 [07:53<02:00,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  80%|                    | 397/497 [07:54<01:59,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  80%|                    | 397/497 [07:54<01:59,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  80%|                    | 398/497 [07:55<01:58,  1.19s/it, loss=0.12, v_num=75]Epoch 0:  80%|                    | 398/497 [07:55<01:58,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  80%|                    | 399/497 [07:56<01:57,  1.19s/it, loss=0.125, v_num=75]Epoch 0:  80%|                    | 399/497 [07:56<01:57,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  80%|                   | 400/497 [07:57<01:55,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  80%|                   | 400/497 [07:57<01:55,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  81%|                   | 401/497 [07:59<01:54,  1.19s/it, loss=0.128, v_num=75]Epoch 0:  81%|                   | 401/497 [07:59<01:54,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  81%|                   | 402/497 [08:00<01:53,  1.19s/it, loss=0.123, v_num=75]Epoch 0:  81%|                   | 402/497 [08:00<01:53,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  81%|                   | 403/497 [08:01<01:52,  1.19s/it, loss=0.122, v_num=75]Epoch 0:  81%|                   | 403/497 [08:01<01:52,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  81%|                   | 404/497 [08:02<01:51,  1.19s/it, loss=0.121, v_num=75]Epoch 0:  81%|                  | 404/497 [08:02<01:51,  1.19s/it, loss=0.0995, v_num=75]Epoch 0:  81%|                  | 405/497 [08:03<01:49,  1.19s/it, loss=0.0995, v_num=75]Epoch 0:  81%|                   | 405/497 [08:03<01:49,  1.19s/it, loss=0.1, v_num=75]Adjusting learning rate of group 0 to 9.9384e-04.
Epoch 0:  82%|                  | 406/497 [08:05<01:48,  1.19s/it, loss=0.1, v_num=75]Epoch 0:  82%|                  | 406/497 [08:05<01:48,  1.19s/it, loss=0.0923, v_num=75]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|                                                                                                                                   | 0/91 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                                                                      | 0/91 [00:00<?, ?it/s][Atorch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   1%|                                                                                                            | 1/91 [00:00<00:23,  3.84it/s][AEpoch 0:  82%|                  | 407/497 [08:05<01:47,  1.19s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   2%|                                                                                                           | 2/91 [00:00<00:24,  3.65it/s][AEpoch 0:  82%|                  | 408/497 [08:05<01:45,  1.19s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   3%|                                                                                                          | 3/91 [00:00<00:24,  3.59it/s][AEpoch 0:  82%|                 | 409/497 [08:06<01:44,  1.19s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   4%|                                                                                                         | 4/91 [00:01<00:24,  3.57it/s][AEpoch 0:  82%|                 | 410/497 [08:06<01:43,  1.19s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   5%|                                                                                                        | 5/91 [00:01<00:24,  3.55it/s][AEpoch 0:  83%|                 | 411/497 [08:06<01:41,  1.18s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   7%|                                                                                                      | 6/91 [00:01<00:23,  3.54it/s][AEpoch 0:  83%|                 | 412/497 [08:06<01:40,  1.18s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   8%|                                                                                                     | 7/91 [00:01<00:23,  3.54it/s][AEpoch 0:  83%|                 | 413/497 [08:07<01:39,  1.18s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:   9%|                                                                                                    | 8/91 [00:02<00:23,  3.52it/s][AEpoch 0:  83%|                | 414/497 [08:07<01:37,  1.18s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  10%|                                                                                                   | 9/91 [00:02<00:23,  3.52it/s][AEpoch 0:  84%|                | 415/497 [08:07<01:36,  1.18s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  11%|                                                                                                 | 10/91 [00:02<00:23,  3.52it/s][AEpoch 0:  84%|                | 416/497 [08:08<01:35,  1.17s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  12%|                                                                                               | 11/91 [00:03<00:22,  3.52it/s][AEpoch 0:  84%|                | 417/497 [08:08<01:33,  1.17s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  13%|                                                                                              | 12/91 [00:03<00:22,  3.51it/s][AEpoch 0:  84%|                | 418/497 [08:08<01:32,  1.17s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  14%|                                                                                             | 13/91 [00:03<00:22,  3.51it/s][AEpoch 0:  84%|               | 419/497 [08:08<01:31,  1.17s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  15%|                                                                                            | 14/91 [00:03<00:21,  3.51it/s][AEpoch 0:  85%|               | 420/497 [08:09<01:29,  1.16s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  16%|                                                                                           | 15/91 [00:04<00:21,  3.51it/s][AEpoch 0:  85%|               | 421/497 [08:09<01:28,  1.16s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  18%|                                                                                         | 16/91 [00:04<00:21,  3.51it/s][AEpoch 0:  85%|               | 422/497 [08:09<01:27,  1.16s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  19%|                                                                                        | 17/91 [00:04<00:21,  3.51it/s][AEpoch 0:  85%|               | 423/497 [08:10<01:25,  1.16s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  20%|                                                                                       | 18/91 [00:05<00:20,  3.50it/s][AEpoch 0:  85%|              | 424/497 [08:10<01:24,  1.16s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  21%|                                                                                      | 19/91 [00:05<00:20,  3.50it/s][AEpoch 0:  86%|              | 425/497 [08:10<01:23,  1.15s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  22%|                                                                                     | 20/91 [00:05<00:20,  3.50it/s][AEpoch 0:  86%|              | 426/497 [08:10<01:21,  1.15s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  23%|                                                                                   | 21/91 [00:06<00:20,  3.50it/s][AEpoch 0:  86%|              | 427/497 [08:11<01:20,  1.15s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  24%|                                                                                  | 22/91 [00:06<00:19,  3.50it/s][AEpoch 0:  86%|              | 428/497 [08:11<01:19,  1.15s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  25%|                                                                                 | 23/91 [00:06<00:19,  3.50it/s][AEpoch 0:  86%|             | 429/497 [08:11<01:17,  1.15s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  26%|                                                                                | 24/91 [00:06<00:19,  3.50it/s][AEpoch 0:  87%|             | 430/497 [08:12<01:16,  1.14s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  27%|                                                                               | 25/91 [00:07<00:18,  3.50it/s][AEpoch 0:  87%|             | 431/497 [08:12<01:15,  1.14s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  29%|                                                                             | 26/91 [00:07<00:18,  3.50it/s][AEpoch 0:  87%|             | 432/497 [08:12<01:14,  1.14s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  30%|                                                                            | 27/91 [00:07<00:18,  3.50it/s][AEpoch 0:  87%|             | 433/497 [08:12<01:12,  1.14s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  31%|                                                                           | 28/91 [00:08<00:18,  3.50it/s][AEpoch 0:  87%|            | 434/497 [08:13<01:11,  1.14s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  32%|                                                                          | 29/91 [00:08<00:17,  3.50it/s][AEpoch 0:  88%|            | 435/497 [08:13<01:10,  1.13s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  33%|                                                                         | 30/91 [00:08<00:17,  3.49it/s][AEpoch 0:  88%|            | 436/497 [08:13<01:09,  1.13s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  34%|                                                                       | 31/91 [00:08<00:17,  3.49it/s][AEpoch 0:  88%|            | 437/497 [08:14<01:07,  1.13s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  35%|                                                                      | 32/91 [00:09<00:16,  3.49it/s][AEpoch 0:  88%|           | 438/497 [08:14<01:06,  1.13s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  36%|                                                                     | 33/91 [00:09<00:16,  3.49it/s][AEpoch 0:  88%|           | 439/497 [08:14<01:05,  1.13s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  37%|                                                                    | 34/91 [00:09<00:16,  3.49it/s][AEpoch 0:  89%|           | 440/497 [08:14<01:04,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  38%|                                                                   | 35/91 [00:10<00:16,  3.49it/s][AEpoch 0:  89%|           | 441/497 [08:15<01:02,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  40%|                                                                  | 36/91 [00:10<00:15,  3.49it/s][AEpoch 0:  89%|           | 442/497 [08:15<01:01,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  41%|                                                                | 37/91 [00:10<00:15,  3.49it/s][AEpoch 0:  89%|          | 443/497 [08:15<01:00,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  42%|                                                               | 38/91 [00:10<00:15,  3.49it/s][AEpoch 0:  89%|          | 444/497 [08:16<00:59,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  43%|                                                              | 39/91 [00:11<00:14,  3.49it/s][AEpoch 0:  90%|          | 445/497 [08:16<00:57,  1.12s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  44%|                                                             | 40/91 [00:11<00:14,  3.49it/s][AEpoch 0:  90%|          | 446/497 [08:16<00:56,  1.11s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  45%|                                                            | 41/91 [00:11<00:14,  3.49it/s][AEpoch 0:  90%|          | 447/497 [08:16<00:55,  1.11s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  46%|                                                          | 42/91 [00:12<00:14,  3.49it/s][AEpoch 0:  90%|         | 448/497 [08:17<00:54,  1.11s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  47%|                                                         | 43/91 [00:12<00:13,  3.49it/s][AEpoch 0:  90%|         | 449/497 [08:17<00:53,  1.11s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  48%|                                                        | 44/91 [00:12<00:13,  3.49it/s][AEpoch 0:  91%|         | 450/497 [08:17<00:51,  1.11s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  49%|                                                       | 45/91 [00:12<00:13,  3.49it/s][AEpoch 0:  91%|         | 451/497 [08:18<00:50,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  51%|                                                      | 46/91 [00:13<00:12,  3.49it/s][AEpoch 0:  91%|         | 452/497 [08:18<00:49,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  52%|                                                    | 47/91 [00:13<00:12,  3.49it/s][AEpoch 0:  91%|        | 453/497 [08:18<00:48,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  53%|                                                   | 48/91 [00:13<00:12,  3.49it/s][AEpoch 0:  91%|        | 454/497 [08:18<00:47,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  54%|                                                  | 49/91 [00:14<00:12,  3.49it/s][AEpoch 0:  92%|        | 455/497 [08:19<00:46,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  55%|                                                 | 50/91 [00:14<00:11,  3.49it/s][AEpoch 0:  92%|        | 456/497 [08:19<00:44,  1.10s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  56%|                                                | 51/91 [00:14<00:11,  3.49it/s][AEpoch 0:  92%|        | 457/497 [08:19<00:43,  1.09s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  57%|                                              | 52/91 [00:14<00:11,  3.49it/s][AEpoch 0:  92%|       | 458/497 [08:20<00:42,  1.09s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  58%|                                             | 53/91 [00:15<00:10,  3.49it/s][AEpoch 0:  92%|       | 459/497 [08:20<00:41,  1.09s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  59%|                                            | 54/91 [00:15<00:10,  3.49it/s][AEpoch 0:  93%|       | 460/497 [08:20<00:40,  1.09s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  60%|                                           | 55/91 [00:15<00:10,  3.49it/s][AEpoch 0:  93%|       | 461/497 [08:20<00:39,  1.09s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  62%|                                          | 56/91 [00:16<00:10,  3.49it/s][AEpoch 0:  93%|       | 462/497 [08:21<00:37,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  63%|                                        | 57/91 [00:16<00:09,  3.49it/s][AEpoch 0:  93%|      | 463/497 [08:21<00:36,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  64%|                                       | 58/91 [00:16<00:09,  3.49it/s][AEpoch 0:  93%|      | 464/497 [08:21<00:35,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  65%|                                      | 59/91 [00:16<00:09,  3.49it/s][AEpoch 0:  94%|      | 465/497 [08:22<00:34,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  66%|                                     | 60/91 [00:17<00:08,  3.49it/s][AEpoch 0:  94%|      | 466/497 [08:22<00:33,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  67%|                                    | 61/91 [00:17<00:08,  3.49it/s][AEpoch 0:  94%|      | 467/497 [08:22<00:32,  1.08s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  68%|                                  | 62/91 [00:17<00:08,  3.49it/s][AEpoch 0:  94%|     | 468/497 [08:22<00:31,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  69%|                                 | 63/91 [00:18<00:08,  3.49it/s][AEpoch 0:  94%|     | 469/497 [08:23<00:30,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  70%|                                | 64/91 [00:18<00:07,  3.49it/s][AEpoch 0:  95%|     | 470/497 [08:23<00:28,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  71%|                               | 65/91 [00:18<00:07,  3.49it/s][AEpoch 0:  95%|     | 471/497 [08:23<00:27,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  73%|                              | 66/91 [00:18<00:07,  3.49it/s][AEpoch 0:  95%|     | 472/497 [08:24<00:26,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  74%|                            | 67/91 [00:19<00:06,  3.49it/s][AEpoch 0:  95%|    | 473/497 [08:24<00:25,  1.07s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  75%|                           | 68/91 [00:19<00:06,  3.49it/s][AEpoch 0:  95%|    | 474/497 [08:24<00:24,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  76%|                          | 69/91 [00:19<00:06,  3.49it/s][AEpoch 0:  96%|    | 475/497 [08:24<00:23,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  77%|                         | 70/91 [00:20<00:06,  3.49it/s][AEpoch 0:  96%|    | 476/497 [08:25<00:22,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  78%|                        | 71/91 [00:20<00:05,  3.49it/s][AEpoch 0:  96%|    | 477/497 [08:25<00:21,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  79%|                      | 72/91 [00:20<00:05,  3.49it/s][AEpoch 0:  96%|   | 478/497 [08:25<00:20,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  80%|                     | 73/91 [00:20<00:05,  3.49it/s][AEpoch 0:  96%|   | 479/497 [08:26<00:19,  1.06s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  81%|                    | 74/91 [00:21<00:04,  3.49it/s][AEpoch 0:  97%|   | 480/497 [08:26<00:17,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  82%|                   | 75/91 [00:21<00:04,  3.49it/s][AEpoch 0:  97%|   | 481/497 [08:26<00:16,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  84%|                  | 76/91 [00:21<00:04,  3.49it/s][AEpoch 0:  97%|   | 482/497 [08:26<00:15,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  85%|                | 77/91 [00:22<00:04,  3.49it/s][AEpoch 0:  97%|  | 483/497 [08:27<00:14,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  86%|               | 78/91 [00:22<00:03,  3.49it/s][AEpoch 0:  97%|  | 484/497 [08:27<00:13,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  87%|              | 79/91 [00:22<00:03,  3.49it/s][AEpoch 0:  98%|  | 485/497 [08:27<00:12,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  88%|             | 80/91 [00:22<00:03,  3.49it/s][AEpoch 0:  98%|  | 486/497 [08:28<00:11,  1.05s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  89%|            | 81/91 [00:23<00:02,  3.49it/s][AEpoch 0:  98%|  | 487/497 [08:28<00:10,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  90%|          | 82/91 [00:23<00:02,  3.49it/s][AEpoch 0:  98%| | 488/497 [08:28<00:09,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  91%|         | 83/91 [00:23<00:02,  3.49it/s][AEpoch 0:  98%| | 489/497 [08:28<00:08,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  92%|        | 84/91 [00:24<00:02,  3.49it/s][AEpoch 0:  99%| | 490/497 [08:29<00:07,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  93%|       | 85/91 [00:24<00:01,  3.49it/s][AEpoch 0:  99%| | 491/497 [08:29<00:06,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  95%|      | 86/91 [00:24<00:01,  3.49it/s][AEpoch 0:  99%| | 492/497 [08:29<00:05,  1.04s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  96%|    | 87/91 [00:24<00:01,  3.49it/s][AEpoch 0:  99%|| 493/497 [08:30<00:04,  1.03s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  97%|   | 88/91 [00:25<00:00,  3.49it/s][AEpoch 0:  99%|| 494/497 [08:30<00:03,  1.03s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  98%|  | 89/91 [00:25<00:00,  3.49it/s][AEpoch 0: 100%|| 495/497 [08:30<00:02,  1.03s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0:  99%| | 90/91 [00:25<00:00,  3.49it/s][AEpoch 0: 100%|| 496/497 [08:30<00:01,  1.03s/it, loss=0.0923, v_num=75]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])

Validation DataLoader 0: 100%|| 91/91 [00:26<00:00,  3.49it/s][AEpoch 0: 100%|| 497/497 [08:31<00:00,  1.03s/it, loss=0.0923, v_num=75]Epoch 0: 100%|| 497/497 [08:31<00:00,  1.03s/it, loss=0.0923, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, Val
                                                                                                                                                                           [ATraining_loss 0.1695165798177883
Epoch 0: 100%|| 497/497 [08:32<00:00,  1.03s/it, loss=0.0923, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 0:   0%| | 0/497 [00:00<?, ?it/s, loss=0.0923, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, Validation F2Epoch 1:   0%| | 0/497 [00:00<?, ?it/s, loss=0.0923, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, Validation F2Epoch 1:   0%| | 1/497 [00:01<10:50,  1.31s/it, loss=0.0923, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   0%| | 1/497 [00:01<10:51,  1.31s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   0%| | 2/497 [00:02<10:19,  1.25s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   0%| | 2/497 [00:02<10:20,  1.25s/it, loss=0.0984, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   1%| | 3/497 [00:03<10:09,  1.23s/it, loss=0.0984, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   1%| | 3/497 [00:03<10:09,  1.23s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 4/497 [00:04<10:03,  1.22s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 4/497 [00:04<10:03,  1.22s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 5/497 [00:06<09:59,  1.22s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 5/497 [00:06<09:59,  1.22s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 6/497 [00:07<09:56,  1.22s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 6/497 [00:07<09:56,  1.22s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 7/497 [00:08<09:54,  1.21s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   1%| | 7/497 [00:08<09:54,  1.21s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 8/497 [00:09<09:52,  1.21s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 8/497 [00:09<09:52,  1.21s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 9/497 [00:10<09:50,  1.21s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 9/497 [00:10<09:50,  1.21s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 10/497 [00:12<09:48,  1.21s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   2%| | 10/497 [00:12<09:48,  1.21s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 11/497 [00:13<09:47,  1.21s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   2%| | 11/497 [00:13<09:47,  1.21s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   2%| | 12/497 [00:14<09:45,  1.21s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   2%| | 12/497 [00:14<09:45,  1.21s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 13/497 [00:15<09:44,  1.21s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 13/497 [00:15<09:44,  1.21s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 14/497 [00:16<09:42,  1.21s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 14/497 [00:16<09:42,  1.21s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 15/497 [00:18<09:41,  1.21s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 15/497 [00:18<09:41,  1.21s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 16/497 [00:19<09:39,  1.21s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 16/497 [00:19<09:39,  1.21s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 17/497 [00:20<09:38,  1.21s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   3%| | 17/497 [00:20<09:38,  1.21s/it, loss=0.124, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 18/497 [00:21<09:37,  1.21s/it, loss=0.124, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 18/497 [00:21<09:37,  1.21s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 19/497 [00:22<09:36,  1.21s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 19/497 [00:22<09:36,  1.21s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 20/497 [00:24<09:34,  1.21s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 20/497 [00:24<09:34,  1.21s/it, loss=0.13, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   4%| | 21/497 [00:25<09:33,  1.20s/it, loss=0.13, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   4%| | 21/497 [00:25<09:33,  1.20s/it, loss=0.128, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 22/497 [00:26<09:32,  1.20s/it, loss=0.128, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   4%| | 22/497 [00:26<09:32,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 23/497 [00:27<09:31,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 23/497 [00:27<09:31,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 24/497 [00:28<09:29,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 24/497 [00:28<09:29,  1.21s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 25/497 [00:30<09:28,  1.20s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 25/497 [00:30<09:28,  1.20s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 26/497 [00:31<09:27,  1.20s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 26/497 [00:31<09:27,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 27/497 [00:32<09:26,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   5%| | 27/497 [00:32<09:26,  1.21s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 28/497 [00:33<09:25,  1.20s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 28/497 [00:33<09:25,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 29/497 [00:34<09:23,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 29/497 [00:34<09:23,  1.20s/it, loss=0.133, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 30/497 [00:36<09:22,  1.20s/it, loss=0.133, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 30/497 [00:36<09:22,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 31/497 [00:37<09:21,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 31/497 [00:37<09:21,  1.20s/it, loss=0.139, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 32/497 [00:38<09:20,  1.20s/it, loss=0.139, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   6%| | 32/497 [00:38<09:20,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 33/497 [00:39<09:18,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 33/497 [00:39<09:18,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 34/497 [00:40<09:17,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 34/497 [00:40<09:17,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 35/497 [00:42<09:16,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 35/497 [00:42<09:16,  1.20s/it, loss=0.129, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 36/497 [00:43<09:15,  1.20s/it, loss=0.129, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 36/497 [00:43<09:15,  1.20s/it, loss=0.126, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 37/497 [00:44<09:13,  1.20s/it, loss=0.126, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   7%| | 37/497 [00:44<09:13,  1.20s/it, loss=0.124, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 38/497 [00:45<09:12,  1.20s/it, loss=0.124, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 38/497 [00:45<09:12,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 39/497 [00:46<09:11,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 39/497 [00:46<09:11,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 40/497 [00:48<09:10,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 40/497 [00:48<09:10,  1.20s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 41/497 [00:49<09:09,  1.20s/it, loss=0.125, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 41/497 [00:49<09:09,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 42/497 [00:50<09:07,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   8%| | 42/497 [00:50<09:07,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 43/497 [00:51<09:06,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 43/497 [00:51<09:06,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 44/497 [00:52<09:05,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 44/497 [00:52<09:05,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 45/497 [00:54<09:04,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:   9%| | 45/497 [00:54<09:04,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   9%| | 46/497 [00:55<09:02,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   9%| | 46/497 [00:55<09:02,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   9%| | 47/497 [00:56<09:01,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:   9%| | 47/497 [00:56<09:01,  1.20s/it, loss=0.0989, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  10%| | 48/497 [00:57<09:00,  1.20s/it, loss=0.0989, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  10%| | 48/497 [00:57<09:00,  1.20s/it, loss=0.107, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 49/497 [00:58<08:59,  1.20s/it, loss=0.107, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 49/497 [00:58<08:59,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  10%| | 50/497 [01:00<08:58,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  10%| | 50/497 [01:00<08:58,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 51/497 [01:01<08:56,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 51/497 [01:01<08:56,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 52/497 [01:02<08:55,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  10%| | 52/497 [01:02<08:55,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 53/497 [01:03<08:54,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 53/497 [01:03<08:54,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 54/497 [01:04<08:53,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 54/497 [01:04<08:53,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 55/497 [01:06<08:51,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 55/497 [01:06<08:51,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 56/497 [01:07<08:50,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 56/497 [01:07<08:50,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 57/497 [01:08<08:49,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  11%| | 57/497 [01:08<08:49,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 58/497 [01:09<08:48,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 58/497 [01:09<08:48,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 59/497 [01:11<08:47,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 59/497 [01:11<08:47,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  12%| | 60/497 [01:12<08:45,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  12%| | 60/497 [01:12<08:45,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 61/497 [01:13<08:44,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 61/497 [01:13<08:44,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 62/497 [01:14<08:43,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  12%| | 62/497 [01:14<08:43,  1.20s/it, loss=0.0995, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  13%|| 63/497 [01:15<08:42,  1.20s/it, loss=0.0995, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  13%|| 63/497 [01:15<08:42,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 64/497 [01:17<08:41,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 64/497 [01:17<08:41,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 65/497 [01:18<08:39,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 65/497 [01:18<08:39,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 66/497 [01:19<08:38,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 66/497 [01:19<08:38,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 67/497 [01:20<08:37,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  13%|| 67/497 [01:20<08:37,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 68/497 [01:21<08:36,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 68/497 [01:21<08:36,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 69/497 [01:23<08:35,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 69/497 [01:23<08:35,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 70/497 [01:24<08:33,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  14%|| 70/497 [01:24<08:33,  1.20s/it, loss=0.1, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidatEpoch 1:  14%|| 71/497 [01:25<08:32,  1.20s/it, loss=0.1, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidatEpoch 1:  14%|| 71/497 [01:25<08:32,  1.20s/it, loss=0.0992, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  14%|| 72/497 [01:26<08:31,  1.20s/it, loss=0.0992, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  14%|| 72/497 [01:26<08:31,  1.20s/it, loss=0.0974, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  15%|| 73/497 [01:27<08:30,  1.20s/it, loss=0.0974, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  15%|| 73/497 [01:27<08:30,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 74/497 [01:29<08:29,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 74/497 [01:29<08:29,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 75/497 [01:30<08:27,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 75/497 [01:30<08:27,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 76/497 [01:31<08:26,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 76/497 [01:31<08:26,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 77/497 [01:32<08:25,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  15%|| 77/497 [01:32<08:25,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 78/497 [01:33<08:24,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 78/497 [01:33<08:24,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  16%|| 79/497 [01:35<08:23,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  16%|| 79/497 [01:35<08:23,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  16%|| 80/497 [01:36<08:21,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  16%|| 80/497 [01:36<08:21,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 81/497 [01:37<08:20,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 81/497 [01:37<08:20,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 82/497 [01:38<08:19,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  16%|| 82/497 [01:38<08:19,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 83/497 [01:39<08:18,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 83/497 [01:39<08:18,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 84/497 [01:41<08:17,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 84/497 [01:41<08:17,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 85/497 [01:42<08:15,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 85/497 [01:42<08:15,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 86/497 [01:43<08:14,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  17%|| 86/497 [01:43<08:14,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 87/497 [01:44<08:13,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 87/497 [01:44<08:13,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 88/497 [01:45<08:12,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 88/497 [01:45<08:12,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 89/497 [01:47<08:11,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 89/497 [01:47<08:11,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 90/497 [01:48<08:09,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 90/497 [01:48<08:09,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 91/497 [01:49<08:08,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  18%|| 91/497 [01:49<08:08,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 92/497 [01:50<08:07,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 92/497 [01:50<08:07,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 93/497 [01:51<08:06,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 93/497 [01:51<08:06,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  19%|| 94/497 [01:53<08:05,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  19%|| 94/497 [01:53<08:05,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 95/497 [01:54<08:03,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 95/497 [01:54<08:03,  1.20s/it, loss=0.138, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 96/497 [01:55<08:02,  1.20s/it, loss=0.138, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  19%|| 96/497 [01:55<08:02,  1.20s/it, loss=0.137, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 97/497 [01:56<08:01,  1.20s/it, loss=0.137, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 97/497 [01:56<08:01,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 98/497 [01:57<08:00,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 98/497 [01:57<08:00,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 99/497 [01:59<07:59,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 99/497 [01:59<07:59,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  20%|| 100/497 [02:00<07:57,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  20%|| 100/497 [02:00<07:57,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  20%|| 101/497 [02:01<07:56,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  20%|| 101/497 [02:01<07:56,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 102/497 [02:02<07:55,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 102/497 [02:02<07:55,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 103/497 [02:03<07:54,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 103/497 [02:03<07:54,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 104/497 [02:05<07:53,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 104/497 [02:05<07:53,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 105/497 [02:06<07:51,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  21%|| 105/497 [02:06<07:51,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  21%|| 106/497 [02:07<07:50,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  21%|| 106/497 [02:07<07:50,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 107/497 [02:08<07:49,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 107/497 [02:08<07:49,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 108/497 [02:09<07:48,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 108/497 [02:10<07:48,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 109/497 [02:11<07:47,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 109/497 [02:11<07:47,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 110/497 [02:12<07:45,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  22%|| 110/497 [02:12<07:45,  1.20s/it, loss=0.0993, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  22%|| 111/497 [02:13<07:44,  1.20s/it, loss=0.0993, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  22%|| 111/497 [02:13<07:44,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 112/497 [02:14<07:43,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 112/497 [02:14<07:43,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 113/497 [02:16<07:42,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 113/497 [02:16<07:42,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 114/497 [02:17<07:40,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 114/497 [02:17<07:40,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 115/497 [02:18<07:39,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 115/497 [02:18<07:39,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 116/497 [02:19<07:38,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  23%|| 116/497 [02:19<07:38,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 117/497 [02:20<07:37,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 117/497 [02:20<07:37,  1.20s/it, loss=0.0985, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  24%|| 118/497 [02:22<07:36,  1.20s/it, loss=0.0985, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  24%|| 118/497 [02:22<07:36,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 119/497 [02:23<07:34,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 119/497 [02:23<07:34,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 120/497 [02:24<07:33,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 120/497 [02:24<07:33,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 121/497 [02:25<07:32,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  24%|| 121/497 [02:25<07:32,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 122/497 [02:26<07:31,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 122/497 [02:26<07:31,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 123/497 [02:28<07:30,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 123/497 [02:28<07:30,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 124/497 [02:29<07:28,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 124/497 [02:29<07:28,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 125/497 [02:30<07:27,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 125/497 [02:30<07:27,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 126/497 [02:31<07:26,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  25%|| 126/497 [02:31<07:26,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 127/497 [02:32<07:25,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 127/497 [02:32<07:25,  1.20s/it, loss=0.126, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 128/497 [02:34<07:24,  1.20s/it, loss=0.126, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 128/497 [02:34<07:24,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 129/497 [02:35<07:22,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 129/497 [02:35<07:22,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 130/497 [02:36<07:21,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 130/497 [02:36<07:21,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 131/497 [02:37<07:20,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  26%|| 131/497 [02:37<07:20,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 132/497 [02:38<07:19,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 132/497 [02:38<07:19,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  27%|| 133/497 [02:40<07:18,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  27%|| 133/497 [02:40<07:18,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  27%|| 134/497 [02:41<07:16,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  27%|| 134/497 [02:41<07:16,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 135/497 [02:42<07:15,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 135/497 [02:42<07:15,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 136/497 [02:43<07:14,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  27%|| 136/497 [02:43<07:14,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 137/497 [02:44<07:13,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 137/497 [02:44<07:13,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 138/497 [02:46<07:12,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 138/497 [02:46<07:12,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 139/497 [02:47<07:10,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 139/497 [02:47<07:10,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 140/497 [02:48<07:09,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 140/497 [02:48<07:09,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 141/497 [02:49<07:08,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  28%|| 141/497 [02:49<07:08,  1.20s/it, loss=0.0992, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 142/497 [02:50<07:07,  1.20s/it, loss=0.0992, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 142/497 [02:50<07:07,  1.20s/it, loss=0.095, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  29%|| 143/497 [02:52<07:06,  1.20s/it, loss=0.095, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  29%|| 143/497 [02:52<07:06,  1.20s/it, loss=0.086, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  29%|| 144/497 [02:53<07:04,  1.20s/it, loss=0.086, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  29%|| 144/497 [02:53<07:04,  1.20s/it, loss=0.0851, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 145/497 [02:54<07:03,  1.20s/it, loss=0.0851, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 145/497 [02:54<07:03,  1.20s/it, loss=0.0848, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 146/497 [02:55<07:02,  1.20s/it, loss=0.0848, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  29%|| 146/497 [02:55<07:02,  1.20s/it, loss=0.0869, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 147/497 [02:56<07:01,  1.20s/it, loss=0.0869, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 147/497 [02:56<07:01,  1.20s/it, loss=0.0825, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 148/497 [02:58<07:00,  1.20s/it, loss=0.0825, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 148/497 [02:58<07:00,  1.20s/it, loss=0.0818, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 149/497 [02:59<06:58,  1.20s/it, loss=0.0818, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 149/497 [02:59<06:58,  1.20s/it, loss=0.0849, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 150/497 [03:00<06:57,  1.20s/it, loss=0.0849, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 150/497 [03:00<06:57,  1.20s/it, loss=0.0856, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 151/497 [03:01<06:56,  1.20s/it, loss=0.0856, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  30%|| 151/497 [03:01<06:56,  1.20s/it, loss=0.0816, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 152/497 [03:02<06:55,  1.20s/it, loss=0.0816, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 152/497 [03:02<06:55,  1.20s/it, loss=0.0854, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 153/497 [03:04<06:54,  1.20s/it, loss=0.0854, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 153/497 [03:04<06:54,  1.20s/it, loss=0.0847, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 154/497 [03:05<06:52,  1.20s/it, loss=0.0847, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 154/497 [03:05<06:52,  1.20s/it, loss=0.0868, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 155/497 [03:06<06:51,  1.20s/it, loss=0.0868, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 155/497 [03:06<06:51,  1.20s/it, loss=0.0848, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 156/497 [03:07<06:50,  1.20s/it, loss=0.0848, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  31%|| 156/497 [03:07<06:50,  1.20s/it, loss=0.0866, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 157/497 [03:08<06:49,  1.20s/it, loss=0.0866, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 157/497 [03:08<06:49,  1.20s/it, loss=0.0818, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 158/497 [03:10<06:48,  1.20s/it, loss=0.0818, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 158/497 [03:10<06:48,  1.20s/it, loss=0.0807, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 159/497 [03:11<06:46,  1.20s/it, loss=0.0807, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 159/497 [03:11<06:46,  1.20s/it, loss=0.0807, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 160/497 [03:12<06:45,  1.20s/it, loss=0.0807, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 160/497 [03:12<06:45,  1.20s/it, loss=0.0804, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 161/497 [03:13<06:44,  1.20s/it, loss=0.0804, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  32%|| 161/497 [03:13<06:44,  1.20s/it, loss=0.09, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  33%|| 162/497 [03:14<06:43,  1.20s/it, loss=0.09, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  33%|| 162/497 [03:14<06:43,  1.20s/it, loss=0.0947, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 163/497 [03:16<06:41,  1.20s/it, loss=0.0947, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 163/497 [03:16<06:41,  1.20s/it, loss=0.0943, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 164/497 [03:17<06:40,  1.20s/it, loss=0.0943, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 164/497 [03:17<06:40,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  33%|| 165/497 [03:18<06:39,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  33%|| 165/497 [03:18<06:39,  1.20s/it, loss=0.0997, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 166/497 [03:19<06:38,  1.20s/it, loss=0.0997, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  33%|| 166/497 [03:19<06:38,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 167/497 [03:20<06:37,  1.20s/it, loss=0.109, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 167/497 [03:20<06:37,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 168/497 [03:22<06:35,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 168/497 [03:22<06:35,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 169/497 [03:23<06:34,  1.20s/it, loss=0.115, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 169/497 [03:23<06:34,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  34%|| 170/497 [03:24<06:33,  1.20s/it, loss=0.12, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  34%|| 170/497 [03:24<06:33,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 171/497 [03:25<06:32,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  34%|| 171/497 [03:25<06:32,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 172/497 [03:27<06:31,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 172/497 [03:27<06:31,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 173/497 [03:28<06:29,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 173/497 [03:28<06:29,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 174/497 [03:29<06:28,  1.20s/it, loss=0.134, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 174/497 [03:29<06:28,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 175/497 [03:30<06:27,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 175/497 [03:30<06:27,  1.20s/it, loss=0.138, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 176/497 [03:31<06:26,  1.20s/it, loss=0.138, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  35%|| 176/497 [03:31<06:26,  1.20s/it, loss=0.139, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 177/497 [03:33<06:25,  1.20s/it, loss=0.139, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 177/497 [03:33<06:25,  1.20s/it, loss=0.14, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  36%|| 178/497 [03:34<06:23,  1.20s/it, loss=0.14, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  36%|| 178/497 [03:34<06:23,  1.20s/it, loss=0.137, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 179/497 [03:35<06:22,  1.20s/it, loss=0.137, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 179/497 [03:35<06:22,  1.20s/it, loss=0.146, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 180/497 [03:36<06:21,  1.20s/it, loss=0.146, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 180/497 [03:36<06:21,  1.20s/it, loss=0.146, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 181/497 [03:37<06:20,  1.20s/it, loss=0.146, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  36%|| 181/497 [03:37<06:20,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 182/497 [03:39<06:19,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 182/497 [03:39<06:19,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 183/497 [03:40<06:17,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 183/497 [03:40<06:17,  1.20s/it, loss=0.141, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 184/497 [03:41<06:16,  1.20s/it, loss=0.141, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 184/497 [03:41<06:16,  1.20s/it, loss=0.14, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  37%|| 185/497 [03:42<06:15,  1.20s/it, loss=0.14, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  37%|| 185/497 [03:42<06:15,  1.20s/it, loss=0.142, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 186/497 [03:43<06:14,  1.20s/it, loss=0.142, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  37%|| 186/497 [03:43<06:14,  1.20s/it, loss=0.133, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 187/497 [03:45<06:13,  1.20s/it, loss=0.133, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 187/497 [03:45<06:13,  1.20s/it, loss=0.128, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 188/497 [03:46<06:11,  1.20s/it, loss=0.128, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 188/497 [03:46<06:11,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 189/497 [03:47<06:10,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 189/497 [03:47<06:10,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 190/497 [03:48<06:09,  1.20s/it, loss=0.132, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 190/497 [03:48<06:09,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 191/497 [03:49<06:08,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  38%|| 191/497 [03:49<06:08,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 192/497 [03:51<06:07,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 192/497 [03:51<06:07,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 193/497 [03:52<06:05,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 193/497 [03:52<06:05,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  39%|| 194/497 [03:53<06:04,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  39%|| 194/497 [03:53<06:04,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  39%|| 195/497 [03:54<06:03,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  39%|| 195/497 [03:54<06:03,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 196/497 [03:55<06:02,  1.20s/it, loss=0.106, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  39%|| 196/497 [03:55<06:02,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 197/497 [03:57<06:01,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 197/497 [03:57<06:01,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 198/497 [03:58<05:59,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 198/497 [03:58<05:59,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 199/497 [03:59<05:58,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 199/497 [03:59<05:58,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 200/497 [04:00<05:57,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 200/497 [04:00<05:57,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 201/497 [04:01<05:56,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  40%|| 201/497 [04:01<05:56,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 202/497 [04:03<05:55,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 202/497 [04:03<05:55,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 203/497 [04:04<05:53,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 203/497 [04:04<05:53,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 204/497 [04:05<05:52,  1.20s/it, loss=0.112, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 204/497 [04:05<05:52,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 205/497 [04:06<05:51,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 205/497 [04:06<05:51,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 206/497 [04:07<05:50,  1.20s/it, loss=0.103, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  41%|| 206/497 [04:07<05:50,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  42%|| 207/497 [04:09<05:48,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  42%|| 207/497 [04:09<05:48,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  42%|| 208/497 [04:10<05:47,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  42%|| 208/497 [04:10<05:47,  1.20s/it, loss=0.0951, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 209/497 [04:11<05:46,  1.20s/it, loss=0.0951, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 209/497 [04:11<05:46,  1.20s/it, loss=0.0893, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 210/497 [04:12<05:45,  1.20s/it, loss=0.0893, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 210/497 [04:12<05:45,  1.20s/it, loss=0.0948, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 211/497 [04:13<05:44,  1.20s/it, loss=0.0948, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  42%|| 211/497 [04:13<05:44,  1.20s/it, loss=0.0914, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  43%|| 212/497 [04:15<05:42,  1.20s/it, loss=0.0914, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  43%|| 212/497 [04:15<05:42,  1.20s/it, loss=0.0973, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  43%|| 213/497 [04:16<05:41,  1.20s/it, loss=0.0973, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  43%|| 213/497 [04:16<05:41,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 214/497 [04:17<05:40,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 214/497 [04:17<05:40,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 215/497 [04:18<05:39,  1.20s/it, loss=0.111, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 215/497 [04:18<05:39,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 216/497 [04:19<05:38,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  43%|| 216/497 [04:19<05:38,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 217/497 [04:21<05:36,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 217/497 [04:21<05:36,  1.20s/it, loss=0.1, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  44%|| 218/497 [04:22<05:35,  1.20s/it, loss=0.1, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidaEpoch 1:  44%|| 218/497 [04:22<05:35,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 219/497 [04:23<05:34,  1.20s/it, loss=0.105, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 219/497 [04:23<05:34,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 220/497 [04:24<05:33,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 220/497 [04:24<05:33,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 221/497 [04:25<05:32,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  44%|| 221/497 [04:25<05:32,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 222/497 [04:27<05:30,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 222/497 [04:27<05:30,  1.20s/it, loss=0.116, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 223/497 [04:28<05:29,  1.20s/it, loss=0.116, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 223/497 [04:28<05:29,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 224/497 [04:29<05:28,  1.20s/it, loss=0.117, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 224/497 [04:29<05:28,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 225/497 [04:30<05:27,  1.20s/it, loss=0.119, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 225/497 [04:30<05:27,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 226/497 [04:31<05:26,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  45%|| 226/497 [04:31<05:26,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 227/497 [04:33<05:24,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 227/497 [04:33<05:24,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 228/497 [04:34<05:23,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 228/497 [04:34<05:23,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 229/497 [04:35<05:22,  1.20s/it, loss=0.122, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 229/497 [04:35<05:22,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 230/497 [04:36<05:21,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 230/497 [04:36<05:21,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 231/497 [04:37<05:20,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  46%|| 231/497 [04:37<05:20,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  47%|| 232/497 [04:39<05:18,  1.20s/it, loss=0.118, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  47%|| 232/497 [04:39<05:18,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  47%|| 233/497 [04:40<05:17,  1.20s/it, loss=0.11, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  47%|| 233/497 [04:40<05:17,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  47%|| 234/497 [04:41<05:16,  1.20s/it, loss=0.102, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  47%|| 234/497 [04:41<05:16,  1.20s/it, loss=0.0907, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  47%|| 235/497 [04:42<05:15,  1.20s/it, loss=0.0907, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  47%|| 235/497 [04:42<05:15,  1.20s/it, loss=0.0855, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  47%|| 236/497 [04:44<05:14,  1.20s/it, loss=0.0855, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  47%|| 236/497 [04:44<05:14,  1.20s/it, loss=0.0905, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 237/497 [04:45<05:12,  1.20s/it, loss=0.0905, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 237/497 [04:45<05:12,  1.20s/it, loss=0.0881, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 238/497 [04:46<05:11,  1.20s/it, loss=0.0881, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 238/497 [04:46<05:11,  1.20s/it, loss=0.0856, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 239/497 [04:47<05:10,  1.20s/it, loss=0.0856, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 239/497 [04:47<05:10,  1.20s/it, loss=0.0931, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 240/497 [04:48<05:09,  1.20s/it, loss=0.0931, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 240/497 [04:48<05:09,  1.20s/it, loss=0.0941, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 241/497 [04:50<05:08,  1.20s/it, loss=0.0941, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  48%|| 241/497 [04:50<05:08,  1.20s/it, loss=0.0757, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 242/497 [04:51<05:06,  1.20s/it, loss=0.0757, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 242/497 [04:51<05:06,  1.20s/it, loss=0.0867, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 243/497 [04:52<05:05,  1.20s/it, loss=0.0867, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 243/497 [04:52<05:05,  1.20s/it, loss=0.0938, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 244/497 [04:53<05:04,  1.20s/it, loss=0.0938, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 244/497 [04:53<05:04,  1.20s/it, loss=0.0979, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 245/497 [04:54<05:03,  1.20s/it, loss=0.0979, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 245/497 [04:54<05:03,  1.20s/it, loss=0.0957, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 246/497 [04:56<05:02,  1.20s/it, loss=0.0957, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  49%|| 246/497 [04:56<05:02,  1.20s/it, loss=0.0995, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  50%|| 247/497 [04:57<05:00,  1.20s/it, loss=0.0995, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValEpoch 1:  50%|| 247/497 [04:57<05:00,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 248/497 [04:58<04:59,  1.20s/it, loss=0.101, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 248/497 [04:58<04:59,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 249/497 [04:59<04:58,  1.20s/it, loss=0.104, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 249/497 [04:59<04:58,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 250/497 [05:00<04:57,  1.20s/it, loss=0.108, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  50%|| 250/497 [05:00<04:57,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 251/497 [05:02<04:56,  1.20s/it, loss=0.113, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 251/497 [05:02<04:56,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 252/497 [05:03<04:54,  1.20s/it, loss=0.114, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 252/497 [05:03<04:54,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 253/497 [05:04<04:53,  1.20s/it, loss=0.121, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 253/497 [05:04<04:53,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 254/497 [05:05<04:52,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 254/497 [05:05<04:52,  1.20s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 255/497 [05:06<04:51,  1.20s/it, loss=0.131, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  51%|| 255/497 [05:06<04:51,  1.20s/it, loss=0.144, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 256/497 [05:08<04:50,  1.20s/it, loss=0.144, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 256/497 [05:08<04:50,  1.20s/it, loss=0.189, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 257/497 [05:09<04:48,  1.20s/it, loss=0.189, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 257/497 [05:09<04:48,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 258/497 [05:10<04:47,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 258/497 [05:10<04:47,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 259/497 [05:11<04:46,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 259/497 [05:11<04:46,  1.20s/it, loss=0.191, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 260/497 [05:12<04:45,  1.20s/it, loss=0.191, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  52%|| 260/497 [05:12<04:45,  1.20s/it, loss=0.196, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 261/497 [05:14<04:44,  1.20s/it, loss=0.196, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 261/497 [05:14<04:44,  1.20s/it, loss=0.202, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 262/497 [05:15<04:42,  1.20s/it, loss=0.202, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 262/497 [05:15<04:42,  1.20s/it, loss=0.196, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 263/497 [05:16<04:41,  1.20s/it, loss=0.196, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 263/497 [05:16<04:41,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 264/497 [05:17<04:40,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 264/497 [05:17<04:40,  1.20s/it, loss=0.192, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 265/497 [05:18<04:39,  1.20s/it, loss=0.192, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  53%|| 265/497 [05:18<04:39,  1.20s/it, loss=0.195, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 266/497 [05:20<04:38,  1.20s/it, loss=0.195, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 266/497 [05:20<04:38,  1.20s/it, loss=0.194, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 267/497 [05:21<04:36,  1.20s/it, loss=0.194, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 267/497 [05:21<04:36,  1.20s/it, loss=0.192, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 268/497 [05:22<04:35,  1.20s/it, loss=0.192, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 268/497 [05:22<04:35,  1.20s/it, loss=0.195, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 269/497 [05:23<04:34,  1.20s/it, loss=0.195, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 269/497 [05:23<04:34,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 270/497 [05:24<04:33,  1.20s/it, loss=0.193, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  54%|| 270/497 [05:24<04:33,  1.20s/it, loss=0.185, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 271/497 [05:26<04:31,  1.20s/it, loss=0.185, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 271/497 [05:26<04:31,  1.20s/it, loss=0.191, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 272/497 [05:27<04:30,  1.20s/it, loss=0.191, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 272/497 [05:27<04:30,  1.20s/it, loss=0.187, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 273/497 [05:28<04:29,  1.20s/it, loss=0.187, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 273/497 [05:28<04:29,  1.20s/it, loss=0.187, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 274/497 [05:29<04:28,  1.20s/it, loss=0.187, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 274/497 [05:29<04:28,  1.20s/it, loss=0.181, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 275/497 [05:30<04:27,  1.20s/it, loss=0.181, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  55%|| 275/497 [05:30<04:27,  1.20s/it, loss=0.168, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 276/497 [05:32<04:25,  1.20s/it, loss=0.168, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 276/497 [05:32<04:25,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 277/497 [05:33<04:24,  1.20s/it, loss=0.123, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 277/497 [05:33<04:24,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 278/497 [05:34<04:23,  1.20s/it, loss=0.127, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 278/497 [05:34<04:23,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 279/497 [05:35<04:22,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 279/497 [05:35<04:22,  1.20s/it, loss=0.141, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 280/497 [05:36<04:21,  1.20s/it, loss=0.141, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  56%|| 280/497 [05:36<04:21,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  57%|| 281/497 [05:38<04:19,  1.20s/it, loss=0.136, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  57%|| 281/497 [05:38<04:19,  1.20s/it, loss=0.13, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  57%|| 282/497 [05:39<04:18,  1.20s/it, loss=0.13, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValidEpoch 1:  57%|| 282/497 [05:39<04:18,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  57%|| 283/497 [05:40<04:17,  1.20s/it, loss=0.135, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, ValiEpoch 1:  57%|| 283/497 [05:40<04:17,  1.20s/it, loss=0.129, v_num=75, Validation Loss=0.131, Validation IoU=nan.0, Validation Dice=0.941, Validation F1 score=nan.0, Vali